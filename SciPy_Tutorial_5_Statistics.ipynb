{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics (<font color=#0099ff>scipy.stats</font>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting help\n",
    "\n",
    "First of all, all distributions are accompanied with help functions. To obtain just some basic information, we print the relevant docstring: `print(stats.norm.__doc__)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('bounds of distribution lower: %s, upper: %s' % (norm.a, norm.b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = norm()\n",
    "dir(rv)  # reformatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_continu = [d for d in dir(stats) if\n",
    "                isinstance(getattr(stats, d), stats.rv_continuous)]\n",
    "dist_discrete = [d for d in dir(stats) if\n",
    "                 isinstance(getattr(stats, d), stats.rv_discrete)]\n",
    "print('number of continuous distributions: %d' % len(dist_continu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('number of discrete distributions:   %d' % len(dist_discrete))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.cdf(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.cdf([-1., 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "norm.cdf(np.array([-1., 0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.mean(), norm.std(), norm.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.stats(moments=\"mv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.ppf(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.rvs(size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.rvs(size=5, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.rvs(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm.stats(loc=3, scale=4, moments=\"mv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import expon\n",
    "expon.mean(scale=3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform\n",
    "uniform.cdf([0, 1, 2, 3, 4, 5], loc=1, scale=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(norm.rvs(5, size=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape parameters\n",
    "\n",
    "For instance, the gamma distribution with density\n",
    "\n",
    "$$\\gamma(x,a)=\\frac{\\lambda\\big(\\lambda x\\big)^{a-1}}{\\Gamma\\big(a\\big)}e^{-\\lambda x},$$\n",
    "\n",
    "requires the shape parameter $a$. Observe that setting $\\lambda$ can be obtained by setting the `scale` keyword to $1/\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma\n",
    "\n",
    "gamma.numargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma.shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma(1, scale=2.).stats(moments=\"mv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma(a=1, scale=2.).stats(moments=\"mv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Freezing a distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = gamma(1, scale=2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv.mean(), rv.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.t.isf([0.1, 0.05, 0.01], [[10], [11]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.t.isf([0.1, 0.05, 0.01], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.t.isf([0.1, 0.05, 0.01], 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.t.isf([0.1, 0.05, 0.01], [10, 11, 12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific points for discrete distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import hypergeom\n",
    "[M, n, N] = [20, 7, 12]\n",
    "\n",
    "x = np.arange(4)*2\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prb = hypergeom.cdf(x, M, n, N)\n",
    "prb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypergeom.ppf(prb, M, n, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building specific distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making a continuous distribution, i.e., subclassing `rv_continuous`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "class deterministic_gen(stats.rv_continuous):\n",
    "    def _cdf(self, x):\n",
    "        return np.where(x < 0, 0., 1.)\n",
    "    def _stats(self):\n",
    "        return 0., 0., 0., 0.\n",
    "\n",
    "deterministic = deterministic_gen(name=\"deterministic\")\n",
    "deterministic.cdf(np.arange(-3, 3, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deterministic.pdf(np.arange(-3, 3, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "quad(deterministic.pdf, -1e-1, 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quad(deterministic.pdf, -1e-3, 1e-3)  # warning removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subclassing `rv_discrete`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(stats.rv_discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npoints = 20   # number of integer support points of the distribution minus 1\n",
    "npointsh = npoints // 2\n",
    "npointsf = float(npoints)\n",
    "nbound = 4   # bounds for the truncated normal\n",
    "normbound = (1+1/npointsf) * nbound   # actual bounds of truncated normal\n",
    "grid = np.arange(-npointsh, npointsh+2, 1)   # integer grid\n",
    "gridlimitsnorm = (grid-0.5) / npointsh * nbound   # bin limits for the truncnorm\n",
    "gridlimits = grid - 0.5   # used later in the analysis\n",
    "grid = grid[:-1]\n",
    "probs = np.diff(stats.truncnorm.cdf(gridlimitsnorm, -normbound, normbound))\n",
    "gridint = grid\n",
    "\n",
    "normdiscrete = stats.rv_discrete(values=(gridint,\n",
    "             np.round(probs, decimals=7)), name='normdiscrete')\n",
    "\n",
    "print('mean = %6.4f, variance = %6.4f, skew = %6.4f, kurtosis = %6.4f' %\n",
    "      normdiscrete.stats(moments='mvsk'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nd_std = np.sqrt(normdiscrete.stats(moments='v'))\n",
    "\n",
    "n_sample = 500\n",
    "np.random.seed(87655678)   # fix the seed for replicability\n",
    "rvs = normdiscrete.rvs(size=n_sample)\n",
    "f, l = np.histogram(rvs, bins=gridlimits)\n",
    "sfreq = np.vstack([gridint, f, probs*n_sample]).T\n",
    "print(sfreq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = np.hstack([f[:5].sum(), f[5:-5], f[-5:].sum()])\n",
    "p2 = np.hstack([probs[:5].sum(), probs[5:-5], probs[-5:].sum()])\n",
    "ch2, pval = stats.chisquare(f2, p2*n_sample)\n",
    "\n",
    "print('chisquare for normdiscrete: chi2 = %6.3f pvalue = %6.4f' % (ch2, pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(282629734)\n",
    "x = stats.t.rvs(10, size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.min())   # equivalent to np.min(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.max())   # equivalent to np.max(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.mean())  # equivalent to np.mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.var())   # equivalent to np.var(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, v, s, k = stats.t.stats(10, moments='mvsk')\n",
    "n, (smin, smax), sm, sv, ss, sk = stats.describe(x)\n",
    "\n",
    "sstr = '%-14s mean = %6.4f, variance = %6.4f, skew = %6.4f, kurtosis = %6.4f'\n",
    "print(sstr % ('distribution:', m, v, s ,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sstr % ('sample:', sm, sv, ss, sk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-test and KS-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('t-statistic = %6.3f pvalue = %6.4f' %  stats.ttest_1samp(x, m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = (sm-m)/np.sqrt(sv/float(n))  # t-statistic for mean\n",
    "pval = stats.t.sf(np.abs(tt), n-1)*2  # two-sided pvalue = Prob(abs(t)>tt)\n",
    "print('t-statistic = %6.3f pvalue = %6.4f' % (tt, pval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KS-statistic D = %6.3f pvalue = %6.4f' % stats.kstest(x, 't', (10,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('KS-statistic D = %6.3f pvalue = %6.4f' % stats.kstest(x, 'norm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, pval = stats.kstest((x-x.mean())/x.std(), 'norm')\n",
    "print('KS-statistic D = %6.3f pvalue = %6.4f' % (d, pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tails of the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit01, crit05, crit10 = stats.t.ppf([1-0.01, 1-0.05, 1-0.10], 10)\n",
    "print('critical values from ppf at 1%%, 5%% and 10%% %8.4f %8.4f %8.4f' % (crit01, crit05, crit10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('critical values from isf at 1%%, 5%% and 10%% %8.4f %8.4f %8.4f' % tuple(stats.t.isf([0.01,0.05,0.10],10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq01 = np.sum(x>crit01) / float(n) * 100\n",
    "freq05 = np.sum(x>crit05) / float(n) * 100\n",
    "freq10 = np.sum(x>crit10) / float(n) * 100\n",
    "print('sample %%-frequency at 1%%, 5%% and 10%% tail %8.4f %8.4f %8.4f' % (freq01, freq05, freq10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq05l = np.sum(stats.t.rvs(10, size=10000) > crit05) / 10000.0 * 100\n",
    "print('larger sample %%-frequency at 5%% tail %8.4f' % freq05l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tail prob. of normal at 1%%, 5%% and 10%% %8.4f %8.4f %8.4f' %\n",
    "      tuple(stats.norm.sf([crit01, crit05, crit10])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.0, 0.01, 0.05, 0.1, 1-0.10, 1-0.05, 1-0.01, 1.0]\n",
    "crit = stats.t.ppf(quantiles, 10)\n",
    "crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = x.size\n",
    "freqcount = np.histogram(x, bins=crit)[0]\n",
    "tprob = np.diff(quantiles)\n",
    "nprob = np.diff(stats.norm.cdf(crit))\n",
    "tch, tpval = stats.chisquare(freqcount, tprob*n_sample)\n",
    "nch, npval = stats.chisquare(freqcount, nprob*n_sample)\n",
    "print('chisquare for t:      chi2 = %6.2f pvalue = %6.4f' % (tch, tpval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('chisquare for normal: chi2 = %6.2f pvalue = %6.4f' % (nch, npval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdof, tloc, tscale = stats.t.fit(x)\n",
    "nloc, nscale = stats.norm.fit(x)\n",
    "tprob = np.diff(stats.t.cdf(crit, tdof, loc=tloc, scale=tscale))\n",
    "nprob = np.diff(stats.norm.cdf(crit, loc=nloc, scale=nscale))\n",
    "tch, tpval = stats.chisquare(freqcount, tprob*n_sample)\n",
    "nch, npval = stats.chisquare(freqcount, nprob*n_sample)\n",
    "print('chisquare for t:      chi2 = %6.2f pvalue = %6.4f' % (tch, tpval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('chisquare for normal: chi2 = %6.2f pvalue = %6.4f' % (nch, npval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special tests for normal distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('normal skewtest teststat = %6.3f pvalue = %6.4f' % stats.skewtest(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('normal kurtosistest teststat = %6.3f pvalue = %6.4f' % stats.kurtosistest(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('normaltest teststat = %6.3f pvalue = %6.4f' % stats.normaltest(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('normaltest teststat = %6.3f pvalue = %6.4f' %\n",
    "      stats.normaltest((x-x.mean())/x.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('normaltest teststat = %6.3f pvalue = %6.4f' %\n",
    "      stats.normaltest(stats.t.rvs(10, size=100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('normaltest teststat = %6.3f pvalue = %6.4f' %\n",
    "             stats.normaltest(stats.norm.rvs(size=1000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing two samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvs1 = stats.norm.rvs(loc=5, scale=10, size=500)\n",
    "rvs2 = stats.norm.rvs(loc=5, scale=10, size=500)\n",
    "stats.ttest_ind(rvs1, rvs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvs3 = stats.norm.rvs(loc=8, scale=10, size=500)\n",
    "stats.ttest_ind(rvs1, rvs3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kolmogorov-Smirnov test for two samples ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ks_2samp(rvs1, rvs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ks_2samp(rvs1, rvs3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel density estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x1 = np.array([-7, -5, 1, 4, 5], dtype=np.float)\n",
    "kde1 = stats.gaussian_kde(x1)\n",
    "kde2 = stats.gaussian_kde(x1, bw_method='silverman')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(x1, np.zeros(x1.shape), 'b+', ms=20)  # rug plot\n",
    "x_eval = np.linspace(-10, 10, num=200)\n",
    "ax.plot(x_eval, kde1(x_eval), 'k-', label=\"Scott's Rule\")\n",
    "ax.plot(x_eval, kde2(x_eval), 'r-', label=\"Silverman's Rule\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_kde_bandwidth(obj, fac=1./5):\n",
    "    \"\"\"We use Scott's Rule, multiplied by a constant factor.\"\"\"\n",
    "    return np.power(obj.n, -1./(obj.d+4)) * fac\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(x1, np.zeros(x1.shape), 'b+', ms=20)  # rug plot\n",
    "kde3 = stats.gaussian_kde(x1, bw_method=my_kde_bandwidth)\n",
    "ax.plot(x_eval, kde3(x_eval), 'g-', label=\"With smaller BW\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12456)\n",
    "x1 = np.random.normal(size=200)  # random data, normal distribution\n",
    "xs = np.linspace(x1.min()-1, x1.max()+1, 200)\n",
    "\n",
    "kde1 = stats.gaussian_kde(x1)\n",
    "kde2 = stats.gaussian_kde(x1, bw_method='silverman')\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(x1, np.zeros(x1.shape), 'b+', ms=12)  # rug plot\n",
    "ax1.plot(xs, kde1(xs), 'k-', label=\"Scott's Rule\")\n",
    "ax1.plot(xs, kde2(xs), 'b-', label=\"Silverman's Rule\")\n",
    "ax1.plot(xs, stats.norm.pdf(xs), 'r--', label=\"True PDF\")\n",
    "\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('Density')\n",
    "ax1.set_title(\"Normal (top) and Student's T$_{df=5}$ (bottom) distributions\")\n",
    "ax1.legend(loc=1)\n",
    "\n",
    "x2 = stats.t.rvs(5, size=200)  # random data, T distribution\n",
    "xs = np.linspace(x2.min() - 1, x2.max() + 1, 200)\n",
    "\n",
    "kde3 = stats.gaussian_kde(x2)\n",
    "kde4 = stats.gaussian_kde(x2, bw_method='silverman')\n",
    "\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.plot(x2, np.zeros(x2.shape), 'b+', ms=12)  # rug plot\n",
    "ax2.plot(xs, kde3(xs), 'k-', label=\"Scott's Rule\")\n",
    "ax2.plot(xs, kde4(xs), 'b-', label=\"Silverman's Rule\")\n",
    "ax2.plot(xs, stats.t.pdf(xs, 5), 'r--', label=\"True PDF\")\n",
    "\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('Density')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "loc1, scale1, size1 = (-2, 1, 175)\n",
    "loc2, scale2, size2 = (2, 0.2, 50)\n",
    "x2 = np.concatenate([np.random.normal(loc=loc1, scale=scale1, size=size1),\n",
    "                     np.random.normal(loc=loc2, scale=scale2, size=size2)])\n",
    "\n",
    "x_eval = np.linspace(x2.min() - 1, x2.max() + 1, 500)\n",
    "\n",
    "kde = stats.gaussian_kde(x2)\n",
    "kde2 = stats.gaussian_kde(x2, bw_method='silverman')\n",
    "kde3 = stats.gaussian_kde(x2, bw_method=partial(my_kde_bandwidth, fac=0.2))\n",
    "kde4 = stats.gaussian_kde(x2, bw_method=partial(my_kde_bandwidth, fac=0.5))\n",
    "\n",
    "pdf = stats.norm.pdf\n",
    "bimodal_pdf = pdf(x_eval, loc=loc1, scale=scale1) * float(size1) / x2.size + \\\n",
    "              pdf(x_eval, loc=loc2, scale=scale2) * float(size2) / x2.size\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(x2, np.zeros(x2.shape), 'b+', ms=12)\n",
    "ax.plot(x_eval, kde(x_eval), 'k-', label=\"Scott's Rule\")\n",
    "ax.plot(x_eval, kde2(x_eval), 'b-', label=\"Silverman's Rule\")\n",
    "ax.plot(x_eval, kde3(x_eval), 'g-', label=\"Scott * 0.2\")\n",
    "ax.plot(x_eval, kde4(x_eval), 'c-', label=\"Scott * 0.5\")\n",
    "ax.plot(x_eval, bimodal_pdf, 'r--', label=\"Actual PDF\")\n",
    "\n",
    "ax.set_xlim([x_eval.min(), x_eval.max()])\n",
    "ax.legend(loc=2)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure(n):\n",
    "    \"\"\"Measurement model, return two coupled measurements.\"\"\"\n",
    "    m1 = np.random.normal(size=n)\n",
    "    m2 = np.random.normal(scale=0.5, size=n)\n",
    "    return m1+m2, m1-m2\n",
    "\n",
    "m1, m2 = measure(2000)\n",
    "xmin = m1.min()\n",
    "xmax = m1.max()\n",
    "ymin = m2.min()\n",
    "ymax = m2.max()\n",
    "\n",
    "X, Y = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
    "positions = np.vstack([X.ravel(), Y.ravel()])\n",
    "values = np.vstack([m1, m2])\n",
    "kernel = stats.gaussian_kde(values)\n",
    "Z = np.reshape(kernel.evaluate(positions).T, X.shape)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.imshow(np.rot90(Z), cmap=plt.cm.gist_earth_r,\n",
    "          extent=[xmin, xmax, ymin, ymax])\n",
    "ax.plot(m1, m2, 'k.', markersize=2)\n",
    "\n",
    "ax.set_xlim([xmin, xmax])\n",
    "ax.set_ylim([ymin, ymax])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiscale Graph Correlation (MGC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('classic')\n",
    "from scipy.stats import multiscale_graphcorr\n",
    "\n",
    "def mgc_plot(x, y, sim_name, mgc_dict=None, only_viz=False,\n",
    "             only_mgc=False):\n",
    "    \"\"\"Plot sim and MGC-plot\"\"\"\n",
    "    if not only_mgc:\n",
    "        # simulation\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        ax = plt.gca()\n",
    "        ax.set_title(sim_name + \" Simulation\", fontsize=20)\n",
    "        ax.scatter(x, y)\n",
    "        ax.set_xlabel('X', fontsize=15)\n",
    "        ax.set_ylabel('Y', fontsize=15)\n",
    "        ax.axis('equal')\n",
    "        ax.tick_params(axis=\"x\", labelsize=15)\n",
    "        ax.tick_params(axis=\"y\", labelsize=15)\n",
    "        plt.show()\n",
    "    if not only_viz:\n",
    "        # local correlation map\n",
    "        plt.figure(figsize=(8,8))\n",
    "        ax = plt.gca()\n",
    "        mgc_map = mgc_dict[\"mgc_map\"]\n",
    "        # draw heatmap\n",
    "        ax.set_title(\"Local Correlation Map\", fontsize=20)\n",
    "        im = ax.imshow(mgc_map, cmap='YlGnBu')\n",
    "        # colorbar\n",
    "        cbar = ax.figure.colorbar(im, ax=ax)\n",
    "        cbar.ax.set_ylabel(\"\", rotation=-90, va=\"bottom\")\n",
    "        ax.invert_yaxis()\n",
    "        # Turn spines off and create white grid.\n",
    "        for edge, spine in ax.spines.items():\n",
    "            spine.set_visible(False)\n",
    "        # optimal scale\n",
    "        opt_scale = mgc_dict[\"opt_scale\"]\n",
    "        ax.scatter(opt_scale[0], opt_scale[1],\n",
    "                   marker='X', s=200, color='red')\n",
    "        # other formatting\n",
    "        ax.tick_params(bottom=\"off\", left=\"off\")\n",
    "        ax.set_xlabel('#Neighbors for X', fontsize=15)\n",
    "        ax.set_ylabel('#Neighbors for Y', fontsize=15)\n",
    "        ax.tick_params(axis=\"x\", labelsize=15)\n",
    "        ax.tick_params(axis=\"y\", labelsize=15)\n",
    "        ax.set_xlim(0, 100)\n",
    "        ax.set_ylim(0, 100)\n",
    "        plt.show()\n",
    "\n",
    "np.random.seed(12345678)\n",
    "x = np.linspace(-1, 1, num=100)\n",
    "y = x + 0.3 * np.random.random(x.size)\n",
    "\n",
    "mgc_plot(x, y, \"Linear\", only_viz=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, pvalue, mgc_dict = multiscale_graphcorr(x, y)\n",
    "print(\"MGC test statistic: \", round(stat, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"P-value: \", round(pvalue, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgc_plot(x, y, \"Linear\", mgc_dict, only_mgc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345678)\n",
    "unif = np.array(np.random.uniform(0, 5, size=100))\n",
    "x = unif * np.cos(np.pi * unif)\n",
    "y = unif * np.sin(np.pi * unif) + 0.4 * np.random.random(x.size)\n",
    "\n",
    "mgc_plot(x, y, \"Spiral\", only_viz=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat, pvalue, mgc_dict = multiscale_graphcorr(x, y)\n",
    "print(\"MGC test statistic: \", round(stat, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"P-value: \", round(pvalue, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgc_plot(x, y, \"Spiral\", mgc_dict, only_mgc=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
