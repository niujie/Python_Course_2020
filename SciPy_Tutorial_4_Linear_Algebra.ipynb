{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciPy Tutorial 4 - Linear Algebra (<font color=#0099ff>scipy.linalg</font>)\n",
    "When SciPy is built using the optimized ATLAS LAPACK and BLAS libraries, it has very fast linear algebra capabilities. If you dig deep enough, all of the raw LAPACK and BLAS libraries are available for your use for even more speed.\n",
    "\n",
    "All of these linear algebra routines expect an object that can be converted into a 2-D array. The output of these routines is also a 2-D array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scipy.linalg vs numpy.linalg\n",
    "\n",
    "<font color=#0099ff>scipy.linalg</font> contains all the functions in <font color=#0099ff>numpy.linalg</font>. plus some other more advanced ones not contained in `numpy.linalg`.\n",
    "\n",
    "Another advantage of using `scipy.linalg` over `numpy.linalg` is that it is always compiled with BLAS/LAPACK support, while for numpy this is optional. Therefore, the scipy version might be faster depending on how numpy was installed.\n",
    "\n",
    "Therefore, unless you don’t want to add `scipy` as a dependency to your `numpy` program, use `scipy.linalg` instead of `numpy.linalg`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpy.matrix vs 2-D numpy.ndarray\n",
    "\n",
    "`numpy.matrix` is matrix class that has a more convenient interface than `numpy.ndarray` for matrix operations. This class supports, for example, MATLAB-like creation syntax via the semicolon, has matrix multiplication as default for the `*` operator, and contains `I` and `T` members that serve as shortcuts for inverse and transpose:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.mat('[1 2; 3 4]')\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.mat('[5 6]')\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A*b.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite its convenience, the use of the `numpy.matrix` class is discouraged, since it adds nothing that cannot be accomplished with 2-D `numpy.ndarray` objects, and may lead to a confusion of which class is being used. For example, the above code can be rewritten as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg\n",
    "A = np.array([[1,2],[3,4]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linalg.inv(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[5,6]]) #2D array\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A*b #not matrix multiplication!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.dot(b.T) #matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([5,6]) #1D array\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.T  #not matrix transpose!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.dot(b)  #does not matter for multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scipy.linalg` operations can be applied equally to `numpy.matrix` or to 2D `numpy.ndarray` objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic routines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the inverse\n",
    "\n",
    "The inverse of a mtrix $\\mathbf{A}$ is the matrix $\\mathbf{B}$, such that $\\mathbf{AB}=\\mathbf{I}$, where $\\mathbf{I}$ is the identity matrix consisting of ones down the main diagonal. Usually, $\\mathbf{B}$ is denoted $\\mathbf{B}=\\mathbf{A}^{-1}$. In SciPy, the matrix inverse of the NumPy array, A, is obtained using <font color=#0099ff>linalg.inv</font>`(A)`, or using `A.I` if `A` is a Matrix. For example, let\n",
    "\n",
    "$$\n",
    "\\mathbf{A}=\\begin{bmatrix}\n",
    "1 & 3 & 5\\\\\n",
    "2 & 5 & 1\\\\\n",
    "2 & 3 & 8\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "then\n",
    "\n",
    "$$\n",
    "A^{-1}=\\frac{1}{25}\\begin{bmatrix}\n",
    "-37 & 9 & 22\\\\\n",
    "14 & 2 & -9\\\\\n",
    "4 & -3 & 1\n",
    "\\end{bmatrix}\\ =\\ \\begin{bmatrix}\n",
    "-1.48 & 0.36 & 0.88\\\\\n",
    "0.56 & 0.08 & -0.36\\\\\n",
    "0.16 & -0.12 & 0.04\n",
    "\\end{bmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,3,5],[2,5,1],[2,3,8]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linalg.inv(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.dot(linalg.inv(A)) #double check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving a linear system\n",
    "Solving linear systems of equations is straightforward using the scipy command <font color=#0099ff>linalg.solve</font>. This command expects an input matrix and a right-hand side vector. The solution vector is then computed. An option for entering a symmetric matrix is offered, which can speed up the processing when applicable. As an example, suppose it is desired to solve the following simultaneous equations:\n",
    "\n",
    "$$\\begin{align}\n",
    "x+3y+5z&=10\\\\\n",
    "2x+5y+z&=8\\\\\n",
    "2x+3y+8z&=3\n",
    "\\end{align}$$\n",
    "\n",
    "We could find the solution vector using a matrix inverse:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "x\\\\\n",
    "y\\\\\n",
    "z\n",
    "\\end{bmatrix}\\ = \\ \n",
    "\\begin{bmatrix}\n",
    "1 & 3 & 5\\\\\n",
    "2 & 5 & 1\\\\\n",
    "2 & 3 & 8\n",
    "\\end{bmatrix}^{\\ -1}\n",
    "\\begin{bmatrix}\n",
    "10\\\\\n",
    "8\\\\\n",
    "3\n",
    "\\end{bmatrix}\\ = \\ \\frac{1}{25}\\ \n",
    "\\begin{bmatrix}\n",
    "-232\\\\\n",
    "129\\\\\n",
    "19\n",
    "\\end{bmatrix}\\ = \\ \n",
    "\\begin{bmatrix}\n",
    "-9.28\\\\\n",
    "5.16\\\\\n",
    "0.76\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "However, it is better to use the linalg.solve command, which can be faster and more numerically stable. In this case, it, however, gives the same answer as shown in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2], [3, 4]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.array([[5], [6]])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linalg.inv(A).dot(b)  # slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.dot(linalg.inv(A).dot(b)) - b  # check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.solve(A, b)  # fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.dot(np.linalg.solve(A, b)) - b  # check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the determinant\n",
    "The determinant of a square matrix $\\mathbf{A}$ is often denoted $|\\mathbf{A}|$ and is a quantity often used in linear algebra. Suppose $a_{i,j}$ are the elements of the matrix $\\mathbf{A}$ and let $M_{i,j}=|\\mathbf{A}_{i,j}|$ be the determinant of the matrix left by removing the $i^{th}$ row and $j^{th}$ column from $\\mathbf{A}$. Then, for any row $i$,\n",
    "\n",
    "$$|\\mathbf{A}|=\\sum_j(-1)^{i+j}a_{i,j}M_{i,j}.$$\n",
    "\n",
    "This is a recursive way to define the determinant, where the base case is defined by accepting that the determinant of a $1\\times1$ matrix is the only matrix element. In SciPy the determinant can be calculated with <font color=#0099ff>linalg.det</font>. For example, the determinant of\n",
    "\n",
    "$$\\mathbf{A}\\ = \\ \\begin{bmatrix}\n",
    "1 & 3 & 5\\\\\n",
    "2 & 5 & 1\\\\\n",
    "2 & 3 & 8\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "is\n",
    "\n",
    "$$\\begin{align}\n",
    "|\\mathbf{A}|\\ &= \\ 1\\begin{vmatrix}\n",
    "5 & 1\\\\\n",
    "3 & 8\n",
    "\\end{vmatrix}\\ -3\\begin{vmatrix}\n",
    "2 & 1\\\\\n",
    "2 & 8\n",
    "\\end{vmatrix}\\ +5\\begin{vmatrix}\n",
    "2 & 5\\\\\n",
    "2 & 3\n",
    "\\end{vmatrix}\\\\\n",
    "&=\\ 1\\ (5\\cdot8-3\\cdot1)\\ -\\ 3\\ (2\\cdot8-2\\cdot1)\\ +\\ 5\\ (2\\cdot3-2\\cdot5)\\ =-25.\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,2],[3,4]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linalg.det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing norms\n",
    "For vector $x$, the order parameter can be any real number including `inf` or `-inf`. The computed norm is\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{x}\\|\\ =\\ \\begin{cases}\n",
    "\\max|x_i| & \\text{ord }=\\infty\\\\\n",
    "\\min|x_i| & \\text{ord }=-\\infty\\\\\n",
    "\\Big(\\sum_i|x_i|^{\\text{ord}}\\Big)^{1/\\text{ord}} & \\text{ord }<\\infty.\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "For matrix $\\mathbf{A}$, the only valid values for norm are $\\pm2,\\pm1,\\pm\\infty$, and 'fro'. Thus,\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{A}\\|\\ =\\ \\begin{cases}\n",
    "\\max_i\\sum_j|a_{i,j}| & \\text{ord }=\\infty\\\\\n",
    "\\min_i\\sum_j|a_{i,j}| & \\text{ord }=-\\infty\\\\\n",
    "\\max_i\\sum_j|a_{i,j}| & \\text{ord }=1\\\\\n",
    "\\min_i\\sum_j|a_{i,j}| & \\text{ord }=-1\\\\\n",
    "\\max\\sigma_i          & \\text{ord }=2\\\\\n",
    "\\min\\sigma_i          & \\text{ord }=-2\\\\\n",
    "\\sqrt{\\text{trace}(\\mathbf{A}^H\\mathbf{A})} & \\text{ord }=\\text{'fro'}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where $\\sigma_i$ are the singular values of $\\mathbf{A}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.array([[1,2],[3,4]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linalg.norm(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linalg.norm(A,'fro') # frobenius norm is the default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linalg.norm(A,1) # L1 norm (max column sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linalg.norm(A,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linalg.norm(A,np.inf) # L inf norm (max row sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving linear least-squares problems and pseudo-inverses\n",
    "Linear least-squares problems occur in many branches of applied mathematics. In this problem, a set of linear scaling coefficients is sought that allows a model to fit the data. In particular, it is assumed that data \n",
    "$y_i$  is related to data $\\mathbf{x}_i$ through a set of coefficients $c_j$ and model functions $f_j(\\mathbf{x}_i)$ via the model\n",
    "$$y_i=\\sum_jc_jf_j(\\mathbf{x}_i)+\\epsilon_i,$$\n",
    "\n",
    "where $\\epsilon_i$ represents uncertainty in the data. The strategy of least squares is to pick the coefficients \n",
    "$c_j$ to minimize\n",
    "$$J(\\mathbf{c})=\\sum_i\\bigg|y_i-\\sum_jc_jf_j(x_i)\\bigg|^2.$$\n",
    "\n",
    "Theoretically, a global minimum will occur when\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial c_n^*}=0=\\sum_i\\bigg(y_i-\\sum_jc_jf_j\\big(x_i\\big)\\bigg)\\big(-f_n^*\\big(x_i\\big)\\big)$$\n",
    "\n",
    "or\n",
    "\n",
    "$$\\begin{align}\n",
    "\\sum_jc_j\\sum_if_j(x_i)f_n^*(x_i)&=\\sum_iy_if_n^*(x_i)\\\\\n",
    "\\mathbf{A}^H\\mathbf{Ac}&=\\mathbf{A}^H\\mathbf{y},\n",
    "\\end{align}$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\big\\{\\mathbf{A}\\big\\}_{i,j}=f_j\\big(x_i\\big).$$\n",
    "\n",
    "where $\\mathbf{A}^H\\mathbf{A}$ is invertible, then\n",
    "\n",
    "$$\\mathbf{c}=\\big(\\mathbf{A}^H\\mathbf{A}\\big)^{-1}\\mathbf{A}^H\\mathbf{y}=\\mathbf{A}^\\dagger\\mathbf{y},$$\n",
    "\n",
    "where $\\mathbf{A}^\\dagger$ is called the pseudo-inverse of $\\mathbf{A}$. Notice that using this definition of \n",
    "$\\mathbf{A}$ the model can be written\n",
    "\n",
    "$$\\mathbf{y}=\\mathbf{Ac}+\\mathbf{\\epsilon}.$$\n",
    "\n",
    "The command <font color=#0099ff>linalg.lstsq</font> will solve the linear least-squares problem for \n",
    "$\\mathbf{c}$ given $\\mathbf{A}$ and $\\mathbf{y}$. In addition, <font color=#0099ff>linalg.pinv</font> or <font color=#0099ff>linalg.pinv2</font> (uses a different method based on singular value decomposition) will find \n",
    "$\\mathbf{A}^\\dagger$ given $\\mathbf{A}$.\n",
    "\n",
    "The following example and figure demonstrate the use of <font color=#0099ff>linalg.lstsq</font> and <font color=#0099ff>linalg.pinv</font> for solving a data-fitting problem. The data shown below were generated using the model:\n",
    "$$y_i=c_1e^{-x_i}+c_2x_i,$$\n",
    "\n",
    "where $x_i=0.1i$ for $i=1,\\dots,10$, $c_1=5$, and $c_2=4$. Noise is added to $y_i$ and the coefficients $c_1$ and $c_2$ are estimated using linear least squares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "c1, c2 = 5.0, 2.0\n",
    "i = np.r_[1:11]\n",
    "xi = 0.1*i\n",
    "yi = c1*np.exp(-xi) + c2*xi\n",
    "zi = yi + 0.05 * np.max(yi) * np.random.randn(len(yi))\n",
    "\n",
    "A = np.c_[np.exp(-xi)[:, np.newaxis], xi[:, np.newaxis]]\n",
    "c, resid, rank, sigma = linalg.lstsq(A, zi)\n",
    "\n",
    "xi2 = np.r_[0.1:1.0:100j]\n",
    "yi2 = c[0]*np.exp(-xi2) + c[1]*xi2\n",
    "\n",
    "plt.plot(xi,zi,'x',xi2,yi2)\n",
    "plt.axis([0,1.1,3.0,5.5])\n",
    "plt.xlabel('$x_i$')\n",
    "plt.title('Data fitting with linalg.lstsq')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompositions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenvalues and eigenvectors\n",
    "The eigenvalue-eigenvector problem is one of the most commonly employed linear algebra operations. In one popular form, the eigenvalue-eigenvector problem is to find for some square matrix $\\mathbf{A}$ scalars $\\lambda$ and corresponding vectors $\\mathbf{v}$, such that\n",
    "\n",
    "$$\\mathbf{Av}=\\lambda\\mathbf{v}.$$\n",
    "\n",
    "For an $N\\times N$ matrix, there are $N$ (not necessarily distinct) eigenvalues — roots of the (characteristic) polynomial\n",
    "\n",
    "$$|\\mathbf{A}-\\lambda\\mathbf{I}|=0.$$\n",
    "\n",
    "The eigenvectors, $\\mathbf{v}$, are also sometimes called right eigenvectors to distinguish them from another set of left eigenvectors that satisfy\n",
    "\n",
    "$$\\mathbf{v}_L^H\\mathbf{A}=\\lambda\\mathbf{v}_L^H$$\n",
    "\n",
    "or\n",
    "\n",
    "$$\\mathbf{A}^H\\mathbf{v}_L=\\lambda^*\\mathbf{v}_L.$$\n",
    "\n",
    "With its default optional arguments, the command <font color=#0099ff>linalg.eig</font> returns $\\lambda$ and $\\mathbf{v}$. However, it can also return $\\mathbf{v}_L$ and just $\\lambda$ by itself (<font color=#0099ff>linalg.eigvals</font> returns just $\\lambda$ as well).\n",
    "\n",
    "In addition, <font color=#0099ff>linalg.eig</font> can also solve the more general eigenvalue problem\n",
    "\n",
    "$$\\begin{align}\n",
    "\\mathbf{Av}&=\\lambda\\mathbf{Bv}\\\\\n",
    "\\mathbf{A}^H\\mathbf{v}_L&=\\lambda^*\\mathbf{B}^H\\mathbf{v}_L\n",
    "\\end{align}$$\n",
    "\n",
    "for square matrices $\\mathbf{A}$ and $mathbf{B}$. The standard eigenvalue problem is an example of the general eigenvalue problem for $\\mathbf{B}=\\mathbf{I}$. When a generalized eigenvalue problem can be solved, it provides a decomposition of $\\mathbf{A}$ as\n",
    "\n",
    "$$\\mathbf{A}=\\mathbf{BV\\Lambda V}^{-1},$$\n",
    "\n",
    "where $\\mathbf{V}$ is the collection of eigenvectors into columns and $\\Lambda$ is a diagonal matrix of eigenvalues.\n",
    "\n",
    "By definition, eigenvectors are only defined up to a constant scale factor. In SciPy, the scaling factor for the eigenvectors is chosen so that $\\|\\mathbf{v}\\|^2=\\sum_iv_i^2=1$.\n",
    "\n",
    "As an example, consider finding the eigenvalues and eigenvectors of the matrix\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "1 & 5 & 2\\\\\n",
    "2 & 4 & 1\\\\\n",
    "3 & 6 & 2\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "The characteristic polynomial is\n",
    "\n",
    "$$\\begin{align}\n",
    "\\big|\\mathbf{A}-\\lambda\\mathbf{I}\\big|&=\\big(1-\\lambda\\big)\\big[\\big(4-\\lambda\\big)\\big(2-\\lambda\\big)-6\\big]-\\\\\n",
    "                              &\\quad5\\big[2\\big(2-\\lambda\\big)-3\\big]+2\\big[12-3\\big(4-\\lambda\\big)\\big]\\\\\n",
    "                              &=-\\lambda^3+7\\lambda^2+8\\lambda-3.\n",
    "\\end{align}$$\n",
    "\n",
    "The roots of this polynomial are the eigenvalues of $\\mathbf{A}$:\n",
    "\n",
    "$$\\begin{align}\n",
    "\\lambda_1 &= 7.9579\\\\\n",
    "\\lambda_2 &= -1.2577\\\\\n",
    "\\lambda_3 &= 0.2997.\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2], [3, 4]])\n",
    "la, v = linalg.eig(A)\n",
    "l1, l2 = la\n",
    "print(l1, l2)   # eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v[:, 0])   # first eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(v[:, 1])   # second eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(abs(v**2), axis=0))  # eigenvectors are unitary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array(v[:, 0]).T\n",
    "print(linalg.norm(A.dot(v1) - l1*v1))  # check the computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular value decomposition\n",
    "Singular value decomposition (SVD) can be thought of as an extension of the eigenvalue problem to matrices that are not square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,2,3],[4,5,6]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M,N = A.shape\n",
    "U,s,Vh = linalg.svd(A)\n",
    "Sig = linalg.diagsvd(s,M,N)\n",
    "U, Vh = U, Vh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U.dot(Sig.dot(Vh)) #check computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LU decomposition\n",
    "The LU decomposition finds a representation for the $M\\times N$ matrix $\\mathbf{A}$ as\n",
    "\n",
    "$$\\mathbf{A}=\\mathbf{PLU},$$\n",
    "\n",
    "where $\\mathbf{P}$ is an $M\\times M$ permutation matrix (a permutation of the rows of the identity matrix), $\\mathbf{L}$ is in $M\\times K$ lower triangular or trapezoidal matrix ($K=\\min\\big(M,N\\big)$) with unit-diagonal, and $\\mathbf{U}$ is an upper triangular or trapezoidal matrix. The SciPy command for this decomposition is <font color=#0099ff>linalg.lu</font>.\n",
    "\n",
    "Such a decomposition is often useful for solving many simultaneous equations where the left-hand side does not change but the right-hand side does. For example, suppose we are going to solve\n",
    "\n",
    "$$\\mathbf{Ax}_i=\\mathbf{b}_i$$\n",
    "\n",
    "for many different $\\mathbf{b}_i$. The LU decomposition allows this to be written as\n",
    "\n",
    "$$\\mathbf{PLUx}_i=\\mathbf{b}_i.$$\n",
    "\n",
    "Because $\\mathbf{L}$ is lower-triangular, the equation can be solved for $\\mathbf{Ux}_i$ and, finally, $\\mathbf{x}_i$ very rapidly using forward- and back-substitution. An initial time spent factoring $\\mathbf{A}$ allows for very rapid solution of similar systems of equations in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
