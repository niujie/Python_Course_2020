{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Basics of Applied Numerical Methods Using Python - 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "Optimization is the term often used for minimizing or maximizing a function. It is sufficient to consider the problem of minimization only; maximization of $F(x)$ is achieved by simply minimizing $-F(x)$. The function $F(x)$, called the *merit function* or *objective function*, is the quantity that we wish to keep as small as possible, such as the cost or weight.The components of $\\mathbf{x}$, known as the *design variables*, are the quantities that we are free to adjust."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. 1**\n",
    "- Find $x$ that minimizes $f(x)=1.6x^3+3x^2-2x$\n",
    "- Its derivative: $f'(x)=4.8x^2+6x-2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "f = lambda x: 1.6 * x**3 + 3 * x**2 - 2 * x\n",
    "fp = lambda x: 4.8 * x**2 + 6 * x - 2\n",
    "\n",
    "# plot the function and its derivative\n",
    "\n",
    "x = np.linspace(-2, 2, 100)\n",
    "_ = plt.figure(figsize=(12, 8), dpi=120)\n",
    "plt.plot(x, f(x), x, fp(x), x, np.zeros(len(x)), 'k')\n",
    "plt.legend(['f(x)', \"f'(x)\", 'y = 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enlarge the central part\n",
    "\n",
    "x = np.linspace(-0.1, 0.6, 100)\n",
    "_ = plt.figure(figsize=(12, 8), dpi=120)\n",
    "plt.plot(x, f(x), x, fp(x), x, np.zeros(len(x)), 'k')\n",
    "plt.plot(0.2735, -0.2899, 'bo', 0.2735, 0, 'ro')\n",
    "plt.ylim([-0.4, 0.2])\n",
    "plt.legend(['f(x)', \"f'(x)\", 'y = 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = [4.8, 6, -2]\n",
    "np.roots(coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(0.27349411)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin\n",
    "\n",
    "x0 = 0\n",
    "xopt = fmin(f, x0, xtol=1e-8)\n",
    "print('optimal x =', xopt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. 2**\n",
    "- Find the minimum of the function (Rosenbrock, or banana func.)\n",
    "$$F=100\\left(y-x^2\\right)^2+\\left(1-x\\right)^2$$\n",
    "- The partial derivatives of $F$:\n",
    "$$\\left\\{\\begin{aligned}\n",
    "\\frac{\\partial F}{\\partial x}&=-400\\left(y-x^2\\right)x-2\\left(1-x\\right)=0\\\\\n",
    "\\frac{\\partial F}{\\partial x}&=200\\left(y-x^2\\right)=0\n",
    "\\end{aligned}\\right .$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the function first\n",
    "\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "x, y = np.linspace(-2, 2, 100), np.linspace(-1, 3, 100)\n",
    "x, y = np.meshgrid(x, y)\n",
    "F = 100*(y-x**2)**2 + (1-x)**2\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8), dpi=120)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.view_init(45, -100)\n",
    "ax.plot_surface(x, y, F, edgecolor='none')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('F')\n",
    "\n",
    "_ = plt.figure(figsize=(12,8), dpi=120)\n",
    "plt.contourf(x, y, np.log(F), levels=30)\n",
    "plt.plot(1, 1, 'ro')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.colorbar()\n",
    "plt.title('log(F)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 100 * (x[1] - x[0]**2)**2 + (1 - x[0])**2\n",
    "\n",
    "x0 = [0, 0]\n",
    "xopt = fmin(f, x0, xtol=1e-8)\n",
    "print('optimal x =', xopt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. 3**\n",
    "- find the minimum of the function\n",
    "$$x e^{-x^2-y^2}+\\frac{x^2+y^2}{20}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x, y: x * np.exp(-x**2-y**2) + (x**2 + y**2) / 20\n",
    "x, y = np.linspace(-2, 2, 100), np.linspace(-2, 2, 100)\n",
    "x, y = np.meshgrid(x, y)\n",
    "z = f(x, y)\n",
    "\n",
    "_ = plt.figure(figsize=(12, 8), dpi=120)\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(x, y, z, cmap='RdBu_r')\n",
    "ax.contour(x, y, z, zdir='z', offset=np.min(z), levels=20, cmap='RdBu_r')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x[0] * np.exp(-x[0]**2 - x[1]**2) + (x[0]**2 + x[1]**2) / 20\n",
    "\n",
    "x0 = [0, 0]\n",
    "xopt = fmin(f, x0, xtol=1e-8)\n",
    "print('optimal x =', xopt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. 4**\n",
    "- Minimize the same function as in **Ex. 3** and,\n",
    "- subject to $\\frac{xy}{2}+\\left(x+2\\right)^2+\\frac{\\left(y-2\\right)^2}{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def ineq_constraint(x):\n",
    "    return -(x[0]*x[1]/2 + (x[0]+2)**2 + (x[1]-2)**2/2 - 2)\n",
    "\n",
    "con = {'type': 'ineq', 'fun': ineq_constraint}\n",
    "x0 = [1, 1]\n",
    "xopt = minimize(f, x0, constraints=con)\n",
    "xopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x, y: x * np.exp(-x**2-y**2) + (x**2 + y**2) / 20\n",
    "g = lambda x, y: x*y/2 + (x + 2)**2 + (y - 2)**2 / 2\n",
    "x, y = np.linspace(-6, 2, 200), np.linspace(-2, 7, 200)\n",
    "x, y = np.meshgrid(x, y)\n",
    "z1 = f(x, y)\n",
    "z2 = g(x, y)\n",
    "z2[z2 > 2] = None\n",
    "\n",
    "_ = plt.figure(figsize=(12, 8), dpi=120)\n",
    "plt.contour(x, y, z1, levels=30, cmap='RdBu_r')\n",
    "plt.contour(x, y, z2, levels=30)\n",
    "plt.plot(-0.97270938,  0.46860651, 'ro')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. 5** See the example in MATLAB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. 6** Nonlinear Data-Fitting\n",
    "\n",
    "This example shows how to fit a nonlinear function to data using several Optimization Toolbox algorithms.\n",
    "\n",
    "- Problem Setup\n",
    "\n",
    "Consider the following data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = np.array([ \n",
    "   [0.0000,    5.8955],\n",
    "   [0.1000,    3.5639],\n",
    "   [0.2000,    2.5173],\n",
    "   [0.3000,    1.9790],\n",
    "   [0.4000,    1.8990],\n",
    "   [0.5000,    1.3938],\n",
    "   [0.6000,    1.1359],\n",
    "   [0.7000,    1.0096],\n",
    "   [0.8000,    1.0343],\n",
    "   [0.9000,    0.8435],\n",
    "   [1.0000,    0.6856],\n",
    "   [1.1000,    0.6100],\n",
    "   [1.2000,    0.5392],\n",
    "   [1.3000,    0.3946],\n",
    "   [1.4000,    0.3903],\n",
    "   [1.5000,    0.5474],\n",
    "   [1.6000,    0.3459],\n",
    "   [1.7000,    0.1370],\n",
    "   [1.8000,    0.2211],\n",
    "   [1.9000,    0.1704],\n",
    "   [2.0000,    0.2636]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's plot these data points.\n",
    "xdata = Data[:, 0]\n",
    "ydata = Data[:, 1]\n",
    "\n",
    "plt.plot(xdata,ydata,'ro')\n",
    "plt.xlabel('xdata')\n",
    "plt.ylabel('ydata')\n",
    "plt.title('Data points')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to fit the function $y =  c_1e^{-\\lambda_1x} + c_2e^{-\\lambda_2x}$ to the data. \n",
    "\n",
    "**Solution Approach Using _Least Square Curve Fitting_**\n",
    "\n",
    "We arbitrarily set our initial point $\\mathbf{x}_0$ as follows:\n",
    "$$c_1=1,\\lambda_1=1,c_2=1,\\lambda_2=0.$$\n",
    "\n",
    "Then define the curve as a function of the parameters and the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([1, 1, 1, 0])\n",
    "\n",
    "func = lambda xdata, c1, lam1, c2, lam2: c1 * np.exp(-lam1 * xdata) + c2 * np.exp(-lam2 * xdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "popt_good, pcov_good = curve_fit(func, xdata, ydata, p0=x0)\n",
    "print(popt_good)\n",
    "plt.plot(xdata, ydata, 'bo', label='data')\n",
    "plt.plot(xdata, func(xdata, *popt_good), 'r-', label='LSCF')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution Approach Using `fmin`**\n",
    "\n",
    "To solve the problem using `fmin`, we set the objective function as the sum of squares of the residuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_sum_squares = lambda x: np.sum((func(xdata, *x) - ydata)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xopt = fmin(func_sum_squares, x0, xtol=1e-8)\n",
    "print(xopt)\n",
    "plt.plot(xdata, ydata, 'bo', label='data')\n",
    "plt.plot(xdata, func(xdata, *xopt), 'r-', label='fmin fit')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting the Linear and Nonlinear Problems**\n",
    "\n",
    "Notice that the fitting problem is linear in the parameters $c_1$ and $c_2$. This means for any values of $\\lambda_1$ and $\\lambda_2$, we can solve the values of $c_1$ and $c_2$ that solve the least-squares problem.\n",
    "\n",
    "We now rework the problem as a two-dimensional problem, searching for the best values of $\\lambda_1$ and $\\lambda_2$. The values of $c_1$ and $c_2$ are calculated at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitvector(xdata, *lam):\n",
    "    \"\"\"Return value of fitting function.\n",
    "       yEst = FITVECTOR(lam,xdata) returns the value of the fitting function, y\n",
    "       (defined below), at the data points xdata with parameters set to lam.\n",
    "       yEst is returned as a N-by-1 column vector, where N is the number of\n",
    "       data points.\n",
    "    \n",
    "       FITVECTOR assumes the fitting function, y, takes the form\n",
    "    \n",
    "         y =  c(1)*exp(-lam(1)*t) + ... + c(n)*exp(-lam(n)*t)\n",
    "    \n",
    "       with n linear parameters c, and n nonlinear parameters lam.\n",
    "    \n",
    "       To solve for the linear parameters c, we build a matrix A\n",
    "       where the j-th column of A is exp(-lam(j)*xdata) (xdata is a vector).\n",
    "       Then we solve A*c = ydata for the linear least-squares solution c,\n",
    "       where ydata is the observed values of y.\"\"\"\n",
    "\n",
    "    A = np.zeros((np.size(xdata), np.size(lam)))  # build A matrix\n",
    "    for j in range(np.size(lam)):\n",
    "        A[:, j] = np.exp(-lam[j] * xdata)\n",
    "\n",
    "    c = np.linalg.pinv(A).dot(ydata)  # solve A*c = y for linear parameters c\n",
    "    yEst = A.dot(c)  # return the estimated response based on c\n",
    "    return yEst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the problem using least square curve fit, starting from a\n",
    "# two-dimensional initial point lam(1), lam(2):\n",
    "\n",
    "x02 = np.array([1., 0.])\n",
    "popt, pcov = curve_fit(fitvector, xdata, ydata, p0=x02)\n",
    "print(popt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split Problem is More Robust to Initial Guess**\n",
    "\n",
    "Choosing a bad starting point for the original four-parameter problem leads to a local solution that is not global. Choosing a starting point with the same bad $\\lambda_1$ and $\\lambda_2$ values for the split two-parameter problem leads to the global solution. To show this we re-run the original problem with a start point that leads to a relatively bad local solution, and compare the resulting fit with the global solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0bad = np.array([5, 1, 1, 0])\n",
    "popt_bad, pcov_bad = curve_fit(func, xdata, ydata, p0=x0bad)\n",
    "print('bad optimized parms: ', popt_bad)\n",
    "\n",
    "_ = plt.figure(figsize=(12, 8), dpi=120)\n",
    "plt.plot(xdata, ydata, 'bo', label='data')\n",
    "plt.plot(xdata, func(xdata, *popt_bad), 'r-', label='bad fit')\n",
    "plt.plot(xdata, func(xdata, *popt_good), 'b', label='good fit')\n",
    "\n",
    "xopt = fmin(func_sum_squares, x0bad, xtol=1e-8)\n",
    "print(xopt)\n",
    "plt.plot(xdata, func(xdata, *xopt), 'm:', linewidth=4, label='fmin fit')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ex. 7** EXAMPLE 10.7 on *Numerical Methods in Engineering with MATLAB*, 2nd Edition.\n",
    "\n",
    "- The figure shows the cross section of a channel carrying water. To determine $h$, $b$, and $\\theta$ that minimize the length of the wetted perimeter while maintaining a cross-sectional area of 8 $m^2$.\n",
    "\n",
    "![ex7](./images/pcp4_ex7.png)\n",
    "\n",
    "- **Solution** The cross-sectional area of the channel is\n",
    "\n",
    "$$A=\\frac{1}{2}\\left[b+\\left(b+2h\\tan\\theta\\right)\\right]h=\\left(b+h\\tan\\theta\\right)h$$\n",
    "\n",
    "- and the length of the wetted perimeter is\n",
    "\n",
    "$$S=b+2\\left(h\\sec\\theta\\right)$$\n",
    "\n",
    "- The optimization problem is to minimize $S$ subject to the constraint $A-8=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fS = lambda b, h, theta: b + 2 * (h / np.cos(theta*np.pi/180))\n",
    "fA = lambda b, h, theta: (b + h * np.tan(theta*np.pi/180)) * h - 8.0\n",
    "\n",
    "x0 = np.array([2, 2, 0.5])\n",
    "fun = lambda x: fS(x[0], x[1], x[2])\n",
    "gfun = lambda x: fA(x[0], x[1], x[2])\n",
    "\n",
    "con = {'type': 'eq', 'fun': gfun}\n",
    "xopt = minimize(fun, x0, constraints=con)\n",
    "xopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOMEWORK 4\n",
    "\n",
    "1. Find the minimum point of the objective function, $f(x)=\\frac{\\left(x^2-4\\right)^2}{8}-1$.\n",
    "\n",
    "Minimize the two-variable objective functions \n",
    "\n",
    "2. $f\\left(x_1,x_2\\right)=x_1^2-x_1x_2-4x_1+x_2^2-x_2$  \n",
    "<br/>\n",
    "3. $f\\left(x\\right)=x_1^4-16x_1^2-5x_1+x_2^4-16x_2^2-5x_2$  \n",
    "<br/>\n",
    "4. $f\\left(x\\right)=\\left(x_1-0.5\\right)^2\\left(x_1+1\\right)^2+\\left(x_2+1\\right)^2\\left(x_2-1\\right)^2$  \n",
    "<br/>\n",
    "5. Minimize the objective function $f\\left(x\\right)=\\frac{\\sin\\left(\\frac{1}{x}\\right)}{\\left(x-0.2\\right)^2+0.1}$.  \n",
    "<br/>\n",
    "6. Minimize the function $F\\left(x,y\\right)=\\left(x-1\\right)^2+\\left(y-1\\right)^2$, subject to the constraints $x+y\\geq1$ and $x\\geq0.6$. Check the result graphically.  \n",
    "<br/>\n",
    "7. Find the minimum of the function $F\\left(x,y\\right)=6x^2+y^3+xy$ in $y\\geq0$. Verify the result by calculus.  \n",
    "<br/>\n",
    "8. Solve Proglem 7 if the constraint is changed to $y\\leq-2$.  \n",
    "<br/>\n",
    "9. Determine the smallest distance from the point $(1,\\ 2)$ to the parabola $y=x^2$.  \n",
    "<br/>\n",
    "10. The sheet of cardboard is folded along the dashed lines to form a box with an open top. If the volume of the box is to be 1.0 $\\text{m}^3$, determine the dimensions $a$ and $b$ that would use the least amount of cardboard. Verify the result by calculus.\n",
    "![hw10](./images/pcp4_hw10.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
