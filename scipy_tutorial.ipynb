{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SciPy Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hello SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "face = misc.face()\n",
    "plt.imshow(face)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg, optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.info(optimize.fmin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index tricks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(([3], [0]*5, np.arange(-1, 1.002, 2/9.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.r_[3,[0]*5,-1:1:10j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mgrid[0:5,0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mgrid[0:5:4j,0:5:4j]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import poly1d\n",
    "p = poly1d([3,4,5])\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p*p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p.integ(k=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.info(poly1d.integ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p.deriv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.info(poly1d.deriv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p([4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizing functions (<font color=#0099ff>vectorize</font>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addsubtract(a,b):\n",
    "    if a > b:\n",
    "        return a - b\n",
    "    else:\n",
    "        return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_addsubtract = np.vectorize(addsubtract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_addsubtract([0,3,6,9],[1,3,5,7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(10)\n",
    "condlist = [x<3, x>5]\n",
    "choicelist = [x, x**2]\n",
    "np.select(condlist, choicelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special functions (<font color=#0099ff>scipy.special</font>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bessel functions of real order (jv, jn_zeros):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>$x^2\\frac{\\mathrm{d}^2y}{\\mathrm{d}x^2}+x\\frac{\\mathrm{d}y}{\\mathrm{d}x}+(x^2-\\alpha^2)y=0$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import special\n",
    "def drumhead_height(n, k, distance, angle, t):\n",
    "    kth_zero = special.jn_zeros(n, k)[-1]\n",
    "    return np.cos(t) * np.cos(n*angle) * special.jn(n, distance*kth_zero)\n",
    "theta = np.r_[0:2*np.pi:50j]\n",
    "radius = np.r_[0:1:50j]\n",
    "x = np.array([r * np.cos(theta) for r in radius])\n",
    "y = np.array([r * np.sin(theta) for r in radius])\n",
    "z = np.array([drumhead_height(1, 1, r, theta, 0.5) for r in radius])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "ax.plot_surface(x, y, z, rstride=1, cstride=1, cmap=cm.jet)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration (<font color=#0099ff>scipy.integrate</font>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.integrate as integrate\n",
    "help(integrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General integration (<font color=#0099ff>quad</font>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrate a bessel function **jv(2.5, x)** along the interval [0, 4.5]:\n",
    "<center>$I=\\int^{4.5}_{0}{J_{2.5}(x)}\\ \\mathrm{d}x$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special as special\n",
    "result = integrate.quad(lambda x: special.jv(2.5,x), 0, 4.5)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import sqrt, sin, cos, pi\n",
    "I = sqrt(2/pi)*(18.0/27*sqrt(2)*cos(4.5) - 4.0/27*sqrt(2)*sin(4.5) +\n",
    "                sqrt(2*pi) * special.fresnel(3/sqrt(pi))[0])\n",
    "I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abs(result[0]-I))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the true value of the integral is:\n",
    "<center>$I=\\sqrt{\\frac{2}{\\pi}}\\Big(\\frac{18}{27}\\sqrt{2}\\cos(4.5)-\\frac{4}{27}\\sqrt{2}\\sin(4.5)+\\sqrt{2\\pi}\\ Si\\ \\Big(\\frac{3}{\\sqrt{\\pi}}\\Big)\\Big)$</center>\n",
    "where\n",
    "<center>$Si(x)=\\int_{0}^{x}{\\sin(\\frac{\\pi}{2}t^2)}\\ \\mathrm{d}t$.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the following integral:\n",
    "<center>$I(a,b)=\\int_{0}^{1}{ax^2+b}\\ \\mathrm{d}x$.</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "\n",
    "def integrand(x, a, b):\n",
    "    return a*x**2 + b\n",
    "\n",
    "a = 2\n",
    "b = 1\n",
    "I = quad(integrand, 0, 1, args=(a,b))\n",
    "I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the following exponential integral from 1 to $\\infty$:\n",
    "<center>$E_n(x)=\\int_{1}^{\\infty}\\frac{e^{-xt}}{t^n}\\ \\mathrm{d}t$.</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrand(t, n, x):\n",
    "    return np.exp(-x*t) / t**n\n",
    "\n",
    "def expint(n, x):\n",
    "    return quad(integrand, 1, np.inf, args=(n, x))[0]\n",
    "\n",
    "import numpy as np\n",
    "vec_expint = np.vectorize(expint)\n",
    "\n",
    "vec_expint(3, np.arange(1.0, 4.0, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.special as special\n",
    "special.expn(3, np.arange(1.0,4.0,0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the double integral:\n",
    "<center>$I_n=\\int_{0}^{\\infty}\\int_{1}^{\\infty}\\frac{e^{-xt}}{t^n}\\ \\mathrm{d}t\\ \\mathrm{d}x=\\frac{1}{n}$.</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = quad(lambda x: expint(3, x), 0, np.inf)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I3 = 1.0/3.0\n",
    "print(I3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General multiple integration (<font color=#0099ff>dblquad</font>, <font color=#0099ff>tplquad</font>, <font color=#0099ff>nquad</font>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import quad, dblquad\n",
    "\n",
    "def I(n):\n",
    "    return dblquad(lambda t, x: np.exp(-x*t)/t**n, 0, np.inf, lambda x: 1, lambda x: np.inf)\n",
    "\n",
    "print(I(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(I(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(I(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the following non-constant limits integral:\n",
    "<center>$I=\\int_{y=0}^{1/2}\\int_{x=0}^{1-2y}xy\\ \\mathrm{d}x\\ \\mathrm{d}y=\\frac{1}{96}$.</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import dblquad\n",
    "area = dblquad(lambda x, y: x*y, 0, 0.5, lambda x: 0, lambda x: 1-2*x)\n",
    "area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The integral from above\n",
    "<center>$I_n=\\int_{0}^{\\infty}\\int_{1}^{\\infty}\\frac{e^{-xt}}{t^n}\\ \\mathrm{d}t\\ \\mathrm{d}x=\\frac{1}{n}$</center>\n",
    "can be calculated as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import integrate\n",
    "\n",
    "N = 5\n",
    "def f(t, x):\n",
    "    return np.exp(-x*t) / t**N\n",
    "\n",
    "integrate.nquad(f, [[1, np.inf],[0, np.inf]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The integral from above\n",
    "<center>$I=\\int_{y=0}^{1/2}\\int_{x=0}^{1-2y}xy\\ \\mathrm{d}x\\ \\mathrm{d}y=\\frac{1}{96}$</center>\n",
    "can be evaluted by means of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "    return x*y\n",
    "\n",
    "def bounds_y():\n",
    "    return [0, 0.5]\n",
    "\n",
    "def bounds_x(y):\n",
    "    return [0, 1-2*y]\n",
    "\n",
    "integrate.nquad(f, [bounds_x, bounds_y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrating Using Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def f1(x):\n",
    "    return x**2\n",
    "\n",
    "def f2(x):\n",
    "    return x**3\n",
    "\n",
    "x = np.array([1,3,4])\n",
    "y1 = f1(x)\n",
    "\n",
    "from scipy.integrate import simps\n",
    "\n",
    "I1 = simps(y1, x)\n",
    "print(I1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This corresponds exactly to:\n",
    "<center>$\\int_{1}^{4}x^2\\ \\mathrm{d}x=21$,</center>\n",
    "whereas integrating the second function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = f2(x)\n",
    "I2 = integrate.simps(y2, x)\n",
    "print(I2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "does not correspond to\n",
    "<center>$\\int_{1}^{4}x^3\\ \\mathrm{d}x=63.75$</center>\n",
    "because the order of the polynomial in f2 is larger than two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ordinary differential equations <font color=#0099ff>(solve_ivp</font>)\n",
    "The function <font color=#0099ff>solve_ivp</font> is available in SciPy for integrating a first-order vector differential equation:\n",
    "\n",
    "<center>$\\frac{d\\mathbf{y}}{dt}=\\mathbf{f}(\\mathbf{y},t)$,</center>\n",
    "\n",
    "given initial conditions $\\mathbf{y}(0)=y_0$, where $\\mathbf{y}$ is a length $N$ vector.\n",
    "Suppose to find the solution to the following second-order differential equation:\n",
    "\n",
    "$$\\frac{d^2\\omega}{dz^2}-z\\omega(z)=0$$\n",
    "\n",
    "with initial conditions $\\omega(0)=\\frac{1}{\\sqrt[3]{3^2}\\Gamma\\big(\\frac{2}{3}\\big)}$ and $\\frac{d\\omega}{dz}|_{z=0}=-\\frac{1}{\\sqrt[3]{3}\\Gamma\\big(\\frac{1}{3}\\big)}$. It is known that the solution to this differential equation with these boundary conditions is the Airy function:\n",
    "\n",
    "$$\\omega=\\mathbf{Ai}(z).$$\n",
    "\n",
    "First, convert this ODE into standard form by setting $\\mathbf{y}=\\big[\\frac{d\\omega}{dz},\\omega\\big]$ and $t=z$. Thus, the differential equation becomes\n",
    "\n",
    "$$\n",
    "\\frac{d\\mathbf{y}}{dt}=\n",
    "\\begin{bmatrix}\n",
    "ty_1\\\\\n",
    "y_0\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 & t\\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "y_0\\\\\n",
    "y_1\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "0 & t\\\\\n",
    "1 & 0\n",
    "\\end{bmatrix}\n",
    "\\mathbf{y}.\n",
    "$$\n",
    "\n",
    "In other words,\n",
    "$$\\mathbf{f}(\\mathbf{y},t)=\\mathbf{A}(t)\\mathbf{y}.$$\n",
    "If $\\mathbf{A}(t)$ commutes with $\\int_0^t{\\mathbf{A}(\\tau)}\\ d\\tau$ under matrix multiplication, then this linear differential equation has an exact solution using the matrix exponential:\n",
    "$$\\mathbf{y}\\ (t)=exp\\big(\\int_0^t{\\mathbf{A(\\tau)}\\ d\\tau}\\big)\\mathbf{y}\\ (0),$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import solve_ivp\n",
    "from scipy.special import gamma, airy\n",
    "y1_0 = +1 / 3**(2/3) / gamma(2/3)\n",
    "y0_0 = -1 / 3**(1/3) / gamma(1/3)\n",
    "y0 = [y0_0, y1_0]\n",
    "def func(t, y):\n",
    "    return [t*y[1],y[0]]\n",
    "\n",
    "t_span = [0, 4]\n",
    "sol1 = solve_ivp(func, t_span, y0)\n",
    "print(\"sol1.t: {}\".format(sol1.t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sol1.y[1]: {}\".format(sol1.y[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"airy(sol.t)[0]:  {}\".format(airy(sol1.t)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtol, atol = (1e-8, 1e-8)\n",
    "sol2 = solve_ivp(func, t_span, y0, rtol=rtol, atol=atol)\n",
    "print(\"sol2.y[1][::6]: {}\".format(sol2.y[1][0::6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"airy(sol2.t)[0][::6]: {}\".format(airy(sol2.t)[0][::6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "t = np.linspace(0, 4, 100)\n",
    "sol3 = solve_ivp(func, t_span, y0, t_eval=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(t, y):\n",
    "    return [[0,t], [1,0]]\n",
    "sol4 = solve_ivp(func, t_span, y0, method='Radau', jac=gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization (<font color=#0099ff>scipy.optimize</font>) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Unconstrained minimization of multivariate scalar functions (<font color=#0099ff>minimize</font>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Rosenbrock function of $N$ variables:\n",
    "$$f(\\mathbf{X})=\\sum_{i=2}^{N}100\\big(x_{i+1}-x_i^2\\big)^2+\\big(1-x_i\\big)^2.$$\n",
    "The minimum value of this function is 0 which is achieved when $x_i=1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nelder-Mead Simplex algorithm (`method='Nelder-Mead'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def rosen(x):\n",
    "    \"\"\"The Rosenbrock function\"\"\"\n",
    "    return sum(100.0*(x[1:]-x[:-1]**2.0)**2.0 + (1-x[:-1])**2.0)\n",
    "\n",
    "x0 = np.array([1.3, 0.7, 0.8, 1.9, 1.2])\n",
    "res = minimize(rosen, x0, method='nelder-mead', options={'xatol': 1e-8, 'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplex algorithm is probably the simplest way to minimize a fairly well-behaved function. It requires only function evaluations and is a good choice for simple minimization problems. However, because it does not use any gradient evaluations, it may take longer to find the minimum.\n",
    "\n",
    "Another optimization algorithm that needs only function calls to find the minimum is *Powell’s* method available by setting `method='powell'` in <font color=#0099ff>minimize</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Broyden-Fletcher-Goldfarb-Shanno algorithm (`method='BFGS'`) \n",
    "In order to converge more quickly to the solution, this routine uses the gradient of the objective function. If the gradient is not given by the user, then it is estimated using first-differences. The Broyden-Fletcher-Goldfarb-Shanno (BFGS) method typically requires fewer function calls than the simplex algorithm even when the gradient must be estimated.\n",
    "\n",
    "To demonstrate this algorithm, the Rosenbrock function is again used. The gradient of the Rosenbrock function is the vector:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial f}{\\partial x_j}&=\\sum_{i=1}^{N}200\\big(x_i-x_{i-1}^2\\big)\\big(\\delta_{i,j}-2x_{i-1}\\delta_{i-1,j}\\big)-2\\big(1-x_{i-1}\\big)\\delta_{i-1,j}\\\\\n",
    "&=200\\big(x_j-x_{j-1}^2\\big)-400x_j\\big(x_{j+1}-x_j^2\\big)-2(1-x_j).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This expression is valid for the interior derivatives. Special cases are\n",
    "\n",
    "$$\\begin{align}\n",
    "\\frac{\\partial f}{\\partial x_0} &= -400x_0\\big(x_1-x_0^2\\big)-2(1-x_0),\\\\\n",
    "\\frac{\\partial f}{\\partial x_{N-1}} &= 200\\big(x_{N-1}-x_{N-2}^2\\big).\n",
    "\\end{align}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosen_der(x):\n",
    "    xm = x[1:-1]\n",
    "    xm_m1 = x[:-2]\n",
    "    xm_p1 = x[2:]\n",
    "    der = np.zeros_like(x)\n",
    "    der[1:-1] = 200*(xm-xm_m1**2) - 400*(xm_p1 - xm**2)*xm - 2*(1-xm)\n",
    "    der[0] = -400*x[0]*(x[1]-x[0]**2) - 2*(1-x[0])\n",
    "    der[-1] = 200*(x[-1]-x[-2]**2)\n",
    "    return der\n",
    "\n",
    "res = minimize(rosen, x0, method='BFGS', jac=rosen_der, options={'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Newton-Conjugate-Gradient algorithm (`method='Newton-CG'`)\n",
    "Newton-Conjugate Gradient algorithm is a modified Newton's method and uses a conjugate gradient algorithm to (approximately) invert the local Hessian. Newton's method is based on fitting the function locally to a quadratic form:\n",
    "$$\n",
    "f(x)\\approx f(x_0)+\\nabla f(x_0)\\cdot(x-x_0)+\\frac{1}{2}(x-x_0)^T\\mathbf{H}\\ (x_0)\\ (x-x_0)\n",
    "$$\n",
    "where $\\mathbf{H}\\ (x_0)$ is a matrix of second-derivatives (the Hessian). If the Hessian is positive definite then the local minimum of this function can be found by setting the gradient of the quadratic form to zero, resulting in\n",
    "$$\n",
    "x_{opt}=x_0-\\mathbf{H}^{-1}\\nabla f.\n",
    "$$\n",
    "##### Full Hessian Example:\n",
    "The Hessian of the Rosenbrock function is\n",
    "\n",
    "$$\\begin{align}\n",
    "H_{ij} &= \\frac{\\partial^2f}{\\partial x_i \\partial x_j}=200\\big(\\delta_{i,j}-2x_{i-1}\\delta_{i-1,j}\\big)-400x_i\\big(\\delta_{i+1,j}-2x_i\\delta_{i,j}\\big)-400\\delta_{i,j}\\big(x_{i+1}-x_i^2\\big)+2\\delta_{i,j}\\\\\n",
    "&= \\big(202+1200x_i^2-400x_{i+1}\\big)\\delta_{i,j}-400x_i\\delta_{i+1,j}-400x_{i-1}\\delta_{i-1,j},\n",
    "\\end{align}$$\n",
    "\n",
    "if $i,j\\in[1,N-2$ with $i,j\\in[0,N-1$ defining the $N\\times N$matrix. Other non-zero entries of the matrix are\n",
    "\n",
    "$$\\begin{align}\n",
    "\\frac{\\partial^2f}{\\partial x_0^2}&=1200x_0^2-400x_1+2,\\\\\n",
    "\\frac{\\partial^2f}{\\partial x_0\\partial x_1}=\\frac{\\partial^2f}{\\partial x_1\\partial x_0}&=-400x_0,\\\\\n",
    "\\frac{\\partial^2f}{\\partial x_{N-1}\\partial x_{N-2}}=\\frac{\\partial^2f}{\\partial x_{N-2}\\partial x_{N-1}} &= -400x_{N-2},\\\\\n",
    "\\frac{\\partial^2f}{\\partial x_{N-1}^2} &= 200.\n",
    "\\end{align}$$\n",
    "\n",
    "For example, the Hessian when $N=5$ is\n",
    "\n",
    "$$\n",
    "H=\n",
    "\\begin{bmatrix}\n",
    "1200x_0^2-400x_1+2 &        -400x_0       &          0           &        0             &    0   \\\\\n",
    "      -400x_0      & 202+1200x_1^2-400x_2 &       -400x_1        &        0             &    0   \\\\\n",
    "         0         &        -400x_1       & 202+1200x_2^2-400x_3 &     -400x_2          &    0   \\\\\n",
    "         0         &           0          &       -400x_2        & 202+1200x_3^2-400x_4 & -400x_3\\\\\n",
    "         0         &           0          &          0           &     -400x_3          &  200\\\\\n",
    "\\end{bmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosen_hess(x):\n",
    "    x = np.asarray(x)\n",
    "    H = np.diag(-400*x[:-1],1) - np.diag(400*x[:-1],-1)\n",
    "    diagonal = np.zeros_like(x)\n",
    "    diagonal[0] = 1200*x[0]**2-400*x[1]+2\n",
    "    diagonal[-1] = 200\n",
    "    diagonal[1:-1] = 202 + 1200*x[1:-1]**2 - 400*x[2:]\n",
    "    H = H + np.diag(diagonal)\n",
    "    return H\n",
    "\n",
    "res = minimize(rosen, x0, method='Newton-CG',\n",
    "               jac=rosen_der, hess=rosen_hess,\n",
    "               options={'xtol': 1e-8, 'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hessian product example:\n",
    "For larger minimization problems, storing the entire Hessian matrix can consume considerable time and memory. The Newton-CG algorithm only needs the product of the Hessian times an arbitrary vector. As a result, the user can supply code to compute this product rather than the full Hessian by giving a hess function which take the minimization vector as the first argument and the arbitrary vector as the second argument (along with extra arguments passed to the function to be minimized). If possible, using Newton-CG with the Hessian product option is probably the fastest way to minimize the function.\n",
    "\n",
    "In this case, the product of the Rosenbrock Hessian with an arbitrary vector is not difficult to compute. If \n",
    "$\\mathbf{p}$ is the arbitrary vector, then $\\mathbf{H}\\ (x)\\ \\mathbf{p}$ has elements:\n",
    "$$\n",
    "\\mathbf{H}\\ (x)\\ \\mathbf{p}\\ =\\ \n",
    "\\begin{bmatrix}\n",
    "\\big(1200x_0^2-400x_1+2\\big)p_0-400x_0p_1\\\\\n",
    "\\vdots\\\\\n",
    "-400x_{i-1}p_{i-1}+\\big(202+1200x_i^2-400x_{i+1}\\big)p_i-400x_ip_{i+1}\\\\\n",
    "\\vdots\\\\\n",
    "-400x_{N-2}p_{N-2}+200p_{N-1}\n",
    "\\end{bmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosen_hess_p(x, p):\n",
    "    x = np.asarray(x)\n",
    "    Hp = np.zeros_like(x)\n",
    "    Hp[0] = (1200*x[0]**2 - 400*x[1] + 2)*p[0] - 400*x[0]*p[1]\n",
    "    Hp[1:-1] = -400*x[:-2]*p[:-2]+(202+1200*x[1:-1]**2-400*x[2:])*p[1:-1] \\\n",
    "               -400*x[1:-1]*p[2:]\n",
    "    Hp[-1] = -400*x[-2]*p[-2] + 200*p[-1]\n",
    "    return Hp\n",
    "\n",
    "res = minimize(rosen, x0, method='Newton-CG',\n",
    "               jac=rosen_der, hessp=rosen_hess_p,\n",
    "               options={'xtol': 1e-8, 'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trust-Region Newton-Conjugate-Gradient Algorithm (`method='trust-ncg'`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Full Hessian example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(rosen, x0, method='trust-ncg',\n",
    "               jac=rosen_der, hess=rosen_hess,\n",
    "               options={'gtol': 1e-8, 'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hessian Product example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(rosen, x0, method='trust-ncg',\n",
    "               jac=rosen_der, hessp=rosen_hess_p,\n",
    "               options={'gtol': 1e-8, 'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trust-Region Truncated Generalized Lanczos / Conjugate Gradient Algorithm (`method='trust-krylov'`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Full Hessian example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(rosen, x0, method='trust-krylov',\n",
    "               jac=rosen_der, hess=rosen_hess,\n",
    "               options={'gtol': 1e-8, 'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hessian Product example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(rosen, x0, method='trust-krylov',\n",
    "               jac=rosen_der, hessp=rosen_hess_p,\n",
    "               options={'gtol': 1e-8, 'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trust-Region Nearly Exact Algorithm (`method='trust-exact'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(rosen, x0, method='trust-exact',\n",
    "               jac=rosen_der, hess=rosen_hess,\n",
    "               options={'gtol': 1e-8, 'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constrained minimization of multivariate scalar functions (<font color=#0099ff>minimize</font>)\n",
    "Consider minimization of the Rosenbrock function:\n",
    "$$\\min_{x_0,x_1} 100\\big(x_1-x_0^2\\big)^2+\\big(1-x_0\\big)^2$$\n",
    "subject to:\n",
    "$$\n",
    "x_0+2x_1\\leq1\\\\\n",
    "x_0^2+x_1\\leq1\\\\\n",
    "x_0^2-x_1\\leq1\\\\\n",
    "2x_0+x_1=1\\\\\n",
    "0\\leq x_0\\leq x_1\\\\\n",
    "-0.5\\leq x_1\\leq2.0.\n",
    "$$\n",
    "\n",
    "This optimization problem has the unique solution $[x_0,x_1]=[0.4149,0.1701]$, for which only the first and fourth constraints are active."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trust-Region Constrained Algorithm (`method='trust-constr'`)\n",
    "The trust-region constrained method deals with constrained minimization problems of the form:\n",
    "\n",
    "$$\\min_x f(x)\\text{, subject to: }c^l\\leq c(x)\\leq c^u,\\ x^l\\leq x\\leq x^u.$$\n",
    "\n",
    "##### Defining Bounds Constraints:\n",
    "The bound constraints $0\\leq x_0\\leq1$ and $−0.5\\leq x_1\\leq2.0$ are defined using a <font color=#0099ff>Bounds</font> object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import Bounds\n",
    "bounds = Bounds([0, -0.5], [1.0, 2.0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining Linear Constraints:\n",
    "The constraints $x_0+2x_1\\leq1$ and $2x_0+x_1=1$ can be written in the linear constraint standard format:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "-\\infty\\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "\\leq\n",
    "\\begin{bmatrix}\n",
    "1 & 2\\\\\n",
    "2 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_0\\\\\n",
    "x_1\n",
    "\\end{bmatrix}\n",
    "\\leq\n",
    "\\begin{bmatrix}\n",
    "1\\\\\n",
    "1\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "and defined using a <font color=#0099ff>LinearConstraint</font> object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import LinearConstraint\n",
    "linear_constraint = LinearConstraint([[1, 2], [2, 1]], [-np.inf, 1], [1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining Nonlinear Constraints:\n",
    "The nonlinear constraint:\n",
    "\n",
    "$$\n",
    "C(x)=\n",
    "\\begin{bmatrix}\n",
    "x_0^2+x_1\\\\\n",
    "x_0^2-x_1\n",
    "\\end{bmatrix}\n",
    "\\leq\n",
    "\\begin{bmatrix}\n",
    "1\\\\\n",
    "1\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "with Jacobian matrix:\n",
    "\n",
    "$$\n",
    "J(x)=\n",
    "\\begin{bmatrix}\n",
    "2x_0 & 1\\\\\n",
    "2x_0 & -1\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "and linear combination of the Hessians:\n",
    "\n",
    "$$\n",
    "H(x,v)=\\sum_{i=0}^{1}v_i\\nabla^2c_i(x)=v_0\n",
    "\\begin{bmatrix}\n",
    "2 & 0\\\\\n",
    "0 & 0\n",
    "\\end{bmatrix}\n",
    "+v_1\n",
    "\\begin{bmatrix}\n",
    "2 & 0\\\\\n",
    "0 & 0\n",
    "\\end{bmatrix},\n",
    "$$\n",
    "\n",
    "is defined using a <font color=#0099ff>NonlinearConstraint</font> object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cons_f(x):\n",
    "    return [x[0]**2 + x[1], x[0]**2 - x[1]]\n",
    "\n",
    "def cons_J(x):\n",
    "    return [[2*x[0], 1], [2*x[0], -1]]\n",
    "\n",
    "def cons_H(x, v):\n",
    "    return v[0]*np.array([[2, 0], [0, 0]]) + v[1]*np.array([[2, 0], [0, 0]])\n",
    "\n",
    "from scipy.optimize import NonlinearConstraint\n",
    "\n",
    "nonlinear_constraint = NonlinearConstraint(cons_f, -np.inf, 1, jac=cons_J, hess=cons_H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix\n",
    "\n",
    "def cons_H_sparse(x, v):\n",
    "    return v[0]*csc_matrix([[2, 0], [0, 0]]) + v[1]*csc_matrix([[2, 0], [0, 0]])\n",
    "\n",
    "nonlinear_constraint = NonlinearConstraint(cons_f, -np.inf, 1,\n",
    "                                           jac=cons_J, hess=cons_H_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import LinearOperator\n",
    "\n",
    "def cons_H_linear_operator(x, v):\n",
    "    def matvec(p):\n",
    "        return np.array([p[0]*2*(v[0]+v[1]), 0])\n",
    "    return LinearOperator((2, 2), matvec=matvec)\n",
    "\n",
    "nonlinear_constraint = NonlinearConstraint(cons_f, -np.inf, 1,\n",
    "                                          jac=cons_J, hess=cons_H_linear_operator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import BFGS\n",
    "\n",
    "nonlinear_constraint = NonlinearConstraint(cons_f, -np.inf, 1, jac=cons_J, hess=BFGS())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlinear_constraint = NonlinearConstraint(cons_f, -np.inf, 1, jac=cons_J, hess='2-point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonlinear_constraint = NonlinearConstraint(cons_f, -np.inf, 1, jac='2-point', hess=BFGS())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Solving the Optimization Problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([0.5, 0])\n",
    "res = minimize(rosen, x0, method='trust-constr', jac=rosen_der, hess=rosen_hess,\n",
    "               constraints=[linear_constraint, nonlinear_constraint],\n",
    "               options={'verbose': 1}, bounds=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rosen_hess_linop(x):\n",
    "    def matvec(p):\n",
    "        return rosen_hess_p(x, p)\n",
    "    return LinearOperator((2, 2), matvec=matvec)\n",
    "\n",
    "res = minimize(rosen, x0, method='trust-constr', jac=rosen_der, hess=rosen_hess_linop,\n",
    "               constraints=[linear_constraint, nonlinear_constraint],\n",
    "               options={'verbose': 1}, bounds=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = minimize(rosen, x0, method='trust-constr', jac=rosen_der, hessp=rosen_hess_p,\n",
    "               constraints=[linear_constraint, nonlinear_constraint],\n",
    "               options={'verbose': 1}, bounds=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import SR1\n",
    "\n",
    "res = minimize(rosen, x0, method='trust-constr',  jac=\"2-point\", hess=SR1(),\n",
    "               constraints=[linear_constraint, nonlinear_constraint],\n",
    "               options={'verbose': 1}, bounds=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential Least SQuares Programming (SLSQP) Algorithm (`method='SLSQP'`)\n",
    "The SLSQP method deals with constrained minimization problems of the form:\n",
    "$$\\min_x\\quad f(x)$$\n",
    "subject to:\n",
    "$$\\begin{align}\n",
    "c_j(x)=0,\\ &j\\in\\mathcal{E}\\\\\n",
    "c_j(x)>0,\\ &j\\in\\mathcal{I}\\\\\n",
    "lb_i\\leq x_i\\leq ub_i,\\ &i=1,\\dots,N.\n",
    "\\end{align}$$\n",
    "Where $\\mathcal{E}$ and $\\mathcal{I}$ are sets of indices containing equality and inequality constraints.\n",
    "Both linear and nonlinear constraints are defined as dictionaries with keys `type`, `fun` and `jac`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ineq_cons = {'type': 'ineq',\n",
    "             'fun' : lambda x: np.array([1 - x[0] - 2*x[1],\n",
    "                                         1 - x[0]**2 - x[1],\n",
    "                                         1 - x[0]**2 + x[1]]),\n",
    "             'jac' : lambda x: np.array([[-1.0, -2.0],\n",
    "                                         [-2*x[0], -1.0],\n",
    "                                         [-2*x[0], 1.0]])}\n",
    "eq_cons = {'type': 'eq',\n",
    "           'fun' : lambda x: np.array([2*x[0] + x[1] - 1]),\n",
    "           'jac' : lambda x: np.array([2.0, 1.0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.array([0.5, 0])\n",
    "res = minimize(rosen, x0, method='SLSQP', jac=rosen_der,\n",
    "               constraints=[eq_cons, ineq_cons], options={'ftol': 1e-9, 'disp': True},\n",
    "               bounds=bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eggholder(x):\n",
    "    return (-(x[1] + 47) * np.sin(np.sqrt(abs(x[0]/2 + (x[1]  + 47))))\n",
    "            -x[0] * np.sin(np.sqrt(abs(x[0] - (x[1]  + 47)))))\n",
    "\n",
    "bounds = [(-512, 512), (-512, 512)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "x = np.arange(-512, 513)\n",
    "y = np.arange(-512, 513)\n",
    "xgrid, ygrid = np.meshgrid(x, y)\n",
    "xy = np.stack([xgrid, ygrid])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8), dpi=80)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.view_init(45, -45)\n",
    "ax.plot_surface(xgrid, ygrid, eggholder(xy), cmap='terrain')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('eggholder(x, y)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "results = dict()\n",
    "results['shgo'] = optimize.shgo(eggholder, bounds)\n",
    "results['shgo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['DA'] = optimize.dual_annealing(eggholder, bounds)\n",
    "results['DA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['DE'] = optimize.differential_evolution(eggholder, bounds)\n",
    "results['BH'] = optimize.basinhopping(eggholder, bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['shgo_sobol'] = optimize.shgo(eggholder, bounds, n=200, iters=5,\n",
    "                                      sampling_method='sobol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8), dpi=80)\n",
    "ax = fig.add_subplot(111)\n",
    "im = ax.imshow(eggholder(xy), interpolation='bilinear', origin='lower',\n",
    "               cmap='gray')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "\n",
    "def plot_point(res, marker='o', color=None):\n",
    "    ax.plot(512+res.x[0], 512+res.x[1], marker=marker, color=color, ms=10)\n",
    "\n",
    "plot_point(results['BH'], color='y')  # basinhopping           - yellow\n",
    "plot_point(results['DE'], color='c')  # differential_evolution - cyan\n",
    "plot_point(results['DA'], color='w')  # dual_annealing.        - white\n",
    "\n",
    "# SHGO produces multiple minima, plot them all (with a smaller marker size)\n",
    "plot_point(results['shgo'], color='r', marker='+')\n",
    "plot_point(results['shgo_sobol'], color='r', marker='x')\n",
    "for i in range(results['shgo_sobol'].xl.shape[0]):\n",
    "    ax.plot(512 + results['shgo_sobol'].xl[i, 0],\n",
    "            512 + results['shgo_sobol'].xl[i, 1],\n",
    "            'ro', ms=2)\n",
    "\n",
    "ax.set_xlim([-4, 514*2])\n",
    "ax.set_ylim([-4, 514*2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least-squares minimization (least_squares)\n",
    "SciPy is capable of solving robustified bound-constrained nonlinear least-squares problems:\n",
    "$$\n",
    "\\min_x\\frac{1}{2}\\sum_{i=1}^{m}\\rho\\big(f_i(x)^2\\big)\\\\\n",
    "\\text{subject to }lb\\leq x\\leq ub\n",
    "$$\n",
    "\n",
    "Here $f_i(x)$ are smooth functions from $\\mathbb{R}^n$ to $\\mathbb{R}$, we refer to them as residuals. $\\rho(\\cdot)$ is a loss function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of solving a fitting problem\n",
    "$$f_i(x)=\\frac{x_0(u_i^2+u_ix_1)}{u_i^2+u_ix_2+x_3}-y_i,\\quad i=0,\\dots,10,$$\n",
    "where $y_i$ are measurement values and $u_i$ are values of the independent variable. The unkown vector of parameters is $\\mathbf{x}=(x_0,x_1,x_2,x_3)^T$. The closed form of Jacobian matrix is:\n",
    "$$\\begin{align}\n",
    "J_{i0}&=\\frac{\\partial f_i}{\\partial x_0}=\\frac{u_i^2+u_ix_1}{u_i^2+u_ix_2+x_3}\\\\\n",
    "J_{i1}&=\\frac{\\partial f_i}{\\partial x_1}=\\frac{u_ix_0}{u_i^2+u_ix_2+x_3}\\\\\n",
    "J_{i2}&=\\frac{\\partial f_i}{\\partial x_2}=-\\frac{x_0(u_i^2+u_ix_1)u_i}{(u_i^2+u_ix_2+x_3)^2}\\\\\n",
    "J_{i3}&=\\frac{\\partial f_i}{\\partial x_3}=-\\frac{x_0(u_i^2+u_ix_1)}{(u_i^2+u_ix_2+x_3)^2}\\\\\n",
    "\\end{align}$$\n",
    "\n",
    "To find a physically meaningful solution, avoid potential division by zero and assure convergence to the global minimum we impose constraints $0\\leq x_j \\leq 100,\\ j=0,1,2,3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import least_squares\n",
    "\n",
    "def model(x, u):\n",
    "    return x[0] * (u ** 2 + x[1] * u) / (u ** 2 + x[2] * u + x[3])\n",
    "\n",
    "def fun(x, u, y):\n",
    "    return model(x, u) - y\n",
    "\n",
    "def jac(x, u, y):\n",
    "    J = np.empty((u.size, x.size))\n",
    "    den = u ** 2 + x[2] * u + x[3]\n",
    "    num = u ** 2 + x[1] * u\n",
    "    J[:, 0] = num / den\n",
    "    J[:, 1] = x[0] * u / den\n",
    "    J[:, 2] = -x[0] * num * u / den ** 2\n",
    "    J[:, 3] = -x[0] * num / den ** 2\n",
    "    return J\n",
    "\n",
    "u = np.array([4.0, 2.0, 1.0, 5.0e-1, 2.5e-1, 1.67e-1, 1.25e-1, 1.0e-1,\n",
    "              8.33e-2, 7.14e-2, 6.25e-2])\n",
    "y = np.array([1.957e-1, 1.947e-1, 1.735e-1, 1.6e-1, 8.44e-2, 6.27e-2,\n",
    "              4.56e-2, 3.42e-2, 3.23e-2, 2.35e-2, 2.46e-2])\n",
    "x0 = np.array([2.5, 3.9, 4.15, 3.9])\n",
    "res = least_squares(fun, x0, jac=jac, bounds=(0, 100), args=(u, y), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "u_test = np.linspace(0, 5)\n",
    "y_test = model(res.x, u_test)\n",
    "plt.plot(u, y, 'o', markersize=4, label='data')\n",
    "plt.plot(u_test, y_test, label='fitted model')\n",
    "plt.xlabel(\"u\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate function minimizers (<font color=#0099ff>minimize_scalar</font>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Unconstrained minimization (`method='brent'`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize_scalar\n",
    "f = lambda x: (x - 2) * (x + 1)**2\n",
    "res = minimize_scalar(f, method='brent')\n",
    "print(res.x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bounded minimization (`method='bounded'`)\n",
    "To find the minimum of $J_1(x)$ near $x=5$, <font color=#0099ff>minimize_scalar</font> can be called using the interval $[4,7]$ as a constraint. The result is $x_{min}=5.3314$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import j1\n",
    "res = minimize_scalar(j1, bounds=(4, 7), method='bounded')\n",
    "res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom minimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import OptimizeResult\n",
    "def custmin(fun, x0, args=(), maxfev=None, stepsize=0.1,\n",
    "        maxiter=100, callback=None, **options):\n",
    "    bestx = x0\n",
    "    besty = fun(x0)\n",
    "    funcalls = 1\n",
    "    niter = 0\n",
    "    improved = True\n",
    "    stop = False\n",
    "\n",
    "    while improved and not stop and niter < maxiter:\n",
    "        improved = False\n",
    "        niter += 1\n",
    "        for dim in range(np.size(x0)):\n",
    "            for s in [bestx[dim] - stepsize, bestx[dim] + stepsize]:\n",
    "                testx = np.copy(bestx)\n",
    "                testx[dim] = s\n",
    "                testy = fun(testx, *args)\n",
    "                funcalls += 1\n",
    "                if testy < besty:\n",
    "                    besty = testy\n",
    "                    bestx = testx\n",
    "                    improved = True\n",
    "            if callback is not None:\n",
    "                callback(bestx)\n",
    "            if maxfev is not None and funcalls >= maxfev:\n",
    "                stop = True\n",
    "                break\n",
    "\n",
    "    return OptimizeResult(fun=besty, x=bestx, nit=niter,\n",
    "                          nfev=funcalls, success=(niter > 1))\n",
    "x0 = [1.35, 0.9, 0.8, 1.1, 1.2]\n",
    "res = minimize(rosen, x0, method=custmin, options=dict(stepsize=0.05))\n",
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custmin(fun, bracket, args=(), maxfev=None, stepsize=0.1,\n",
    "        maxiter=100, callback=None, **options):\n",
    "    bestx = (bracket[1] + bracket[0]) / 2.0\n",
    "    besty = fun(bestx)\n",
    "    funcalls = 1\n",
    "    niter = 0\n",
    "    improved = True\n",
    "    stop = False\n",
    "\n",
    "    while improved and not stop and niter < maxiter:\n",
    "        improved = False\n",
    "        niter += 1\n",
    "        for testx in [bestx - stepsize, bestx + stepsize]:\n",
    "            testy = fun(testx, *args)\n",
    "            funcalls += 1\n",
    "            if testy < besty:\n",
    "                besty = testy\n",
    "                bestx = testx\n",
    "                improved = True\n",
    "        if callback is not None:\n",
    "            callback(bestx)\n",
    "        if maxfev is not None and funcalls >= maxfev:\n",
    "            stop = True\n",
    "            break\n",
    "\n",
    "    return OptimizeResult(fun=besty, x=bestx, nit=niter,\n",
    "                          nfev=funcalls, success=(niter > 1))\n",
    "def f(x):\n",
    "    return (x - 2)**2 * (x + 2)**2\n",
    "res = minimize_scalar(f, bracket=(-3.5, 0), method=custmin,\n",
    "                      options=dict(stepsize = 0.05))\n",
    "res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root finding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single-variable transcendental equation:\n",
    "$$x+2\\cos(x)=0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import root\n",
    "def func(x):\n",
    "    return x + 2 * np.cos(x)\n",
    "sol = root(func, 0.3)\n",
    "sol.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sol.fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider now a set of non-linear equations\n",
    "$$\n",
    "x_0\\cos(x_1)=4,\\\\\n",
    "x_0x_1-x_1=5.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func2(x):\n",
    "    f = [x[0] * np.cos(x[1]) - 4,\n",
    "         x[1]*x[0] - x[1] - 5]\n",
    "    df = np.array([[np.cos(x[1]), -x[0] * np.sin(x[1])],\n",
    "                   [x[1], x[0] - 1]])\n",
    "    return f, df\n",
    "sol = root(func2, [1, 1], jac=True, method='lm')\n",
    "sol.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Root finding for large problems\n",
    "Solve the following integrodifferential equation on the square $[0,1\\times[0,1]$:\n",
    "$$\\big(\\partial_x^2+\\partial_y^2\\big)P+5\\Bigg(\\int_0^1\\int_0^1\\cosh(P)\\ dx\\ dy\\Bigg)^2=0$$\n",
    "\n",
    "with the boundary condition $P(x,1)=1$ on the upper edge and $P=0$ elsewhere on the boundary of the square. This can be done by approximating the continuous function $P$ by its values on a grid, $P_{n,m}\\approx P(nh,mh)$, with a small grid spacing $h$. The derivatives and integrals can then be approximated; for instance $\\partial_x^2P(x,y)\\approx (P(x+h,y)-2P(x,y)+P(x-h,y))/h^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import root\n",
    "from numpy import cosh, zeros_like, mgrid, zeros\n",
    "\n",
    "# parameters\n",
    "nx, ny = 75, 75\n",
    "hx, hy = 1./(nx-1), 1./(ny-1)\n",
    "\n",
    "P_left, P_right = 0, 0\n",
    "P_top, P_bottom = 1, 0\n",
    "\n",
    "def residual(P):\n",
    "    d2x = zeros_like(P)\n",
    "    d2y = zeros_like(P)\n",
    "\n",
    "    d2x[1:-1] = (P[2:]   - 2*P[1:-1] + P[:-2]) / hx/hx\n",
    "    d2x[0]    = (P[1]    - 2*P[0]    + P_left)/hx/hx\n",
    "    d2x[-1]   = (P_right - 2*P[-1]   + P[-2])/hx/hx\n",
    "    \n",
    "    d2y[:,1:-1] = (P[:,2:] - 2*P[:,1:-1] + P[:,:-2])/hy/hy\n",
    "    d2y[:,0]    = (P[:,1]  - 2*P[:,0]    + P_bottom)/hy/hy\n",
    "    d2y[:,-1]   = (P_top   - 2*P[:,-1]   + P[:,-2])/hy/hy\n",
    "    \n",
    "    return d2x + d2y + 5*cosh(P).mean()**2\n",
    "\n",
    "# solve\n",
    "guess = zeros((nx, ny), float)\n",
    "sol = root(residual, guess, method='krylov', options={'disp': True})\n",
    "#sol = root(residual, guess, method='broyden2', options={'disp': True, 'max_rank': 50})\n",
    "#sol = root(residual, guess, method='anderson', options={'disp': True, 'M': 10})\n",
    "print('Residual: %g' % abs(residual(sol.x)).max())\n",
    "\n",
    "# visualize\n",
    "import matplotlib.pyplot as plt\n",
    "x, y = mgrid[0:1:(nx*1j), 0:1:(ny*1j)]\n",
    "plt.pcolor(x, y, sol.x)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Still too slow? Preconditioning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import root\n",
    "from scipy.sparse import spdiags, kron\n",
    "from scipy.sparse.linalg import spilu, LinearOperator\n",
    "from numpy import cosh, zeros_like, mgrid, zeros, eye\n",
    "\n",
    "# parameters\n",
    "nx, ny = 75, 75\n",
    "hx, hy = 1./(nx-1), 1./(ny-1)\n",
    "\n",
    "P_left, P_right = 0, 0\n",
    "P_top, P_bottom = 1, 0\n",
    "\n",
    "def get_preconditioner():\n",
    "    \"\"\"Compute the preconditioner M\"\"\"\n",
    "    diags_x = zeros((3, nx))\n",
    "    diags_x[0,:] = 1/hx/hx\n",
    "    diags_x[1,:] = -2/hx/hx\n",
    "    diags_x[2,:] = 1/hx/hx\n",
    "    Lx = spdiags(diags_x, [-1,0,1], nx, nx)\n",
    "\n",
    "    diags_y = zeros((3, ny))\n",
    "    diags_y[0,:] = 1/hy/hy\n",
    "    diags_y[1,:] = -2/hy/hy\n",
    "    diags_y[2,:] = 1/hy/hy\n",
    "    Ly = spdiags(diags_y, [-1,0,1], ny, ny)\n",
    "\n",
    "    J1 = kron(Lx, eye(ny)) + kron(eye(nx), Ly)\n",
    "\n",
    "    # Now we have the matrix `J_1`. We need to find its inverse `M` --\n",
    "    # however, since an approximate inverse is enough, we can use\n",
    "    # the *incomplete LU* decomposition\n",
    "\n",
    "    J1_ilu = spilu(J1)\n",
    "\n",
    "    # This returns an object with a method .solve() that evaluates\n",
    "    # the corresponding matrix-vector product. We need to wrap it into\n",
    "    # a LinearOperator before it can be passed to the Krylov methods:\n",
    "\n",
    "    M = LinearOperator(shape=(nx*ny, nx*ny), matvec=J1_ilu.solve)\n",
    "    return M\n",
    "\n",
    "def solve(preconditioning=True):\n",
    "    \"\"\"Compute the solution\"\"\"\n",
    "    count = [0]\n",
    "\n",
    "    def residual(P):\n",
    "        count[0] += 1\n",
    "\n",
    "        d2x = zeros_like(P)\n",
    "        d2y = zeros_like(P)\n",
    "\n",
    "        d2x[1:-1] = (P[2:]   - 2*P[1:-1] + P[:-2])/hx/hx\n",
    "        d2x[0]    = (P[1]    - 2*P[0]    + P_left)/hx/hx\n",
    "        d2x[-1]   = (P_right - 2*P[-1]   + P[-2])/hx/hx\n",
    "\n",
    "        d2y[:,1:-1] = (P[:,2:] - 2*P[:,1:-1] + P[:,:-2])/hy/hy\n",
    "        d2y[:,0]    = (P[:,1]  - 2*P[:,0]    + P_bottom)/hy/hy\n",
    "        d2y[:,-1]   = (P_top   - 2*P[:,-1]   + P[:,-2])/hy/hy\n",
    "\n",
    "        return d2x + d2y + 5*cosh(P).mean()**2\n",
    "\n",
    "    # preconditioner\n",
    "    if preconditioning:\n",
    "        M = get_preconditioner()\n",
    "    else:\n",
    "        M = None\n",
    "\n",
    "    # solve\n",
    "    guess = zeros((nx, ny), float)\n",
    "\n",
    "    sol = root(residual, guess, method='krylov',\n",
    "               options={'disp': True,\n",
    "                        'jac_options': {'inner_M': M}})\n",
    "    print('Residual', abs(residual(sol.x)).max())\n",
    "    print('Evaluations', count[0])\n",
    "\n",
    "    return sol.x\n",
    "\n",
    "def main():\n",
    "    sol = solve(preconditioning=True)\n",
    "\n",
    "    # visualize\n",
    "    import matplotlib.pyplot as plt\n",
    "    x, y = mgrid[0:1:(nx*1j), 0:1:(ny*1j)]\n",
    "    plt.clf()\n",
    "    plt.pcolor(x, y, sol)\n",
    "    plt.clim(0, 1)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
