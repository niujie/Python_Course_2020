{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Basics of Applied Numerical Methods Using Python - 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overflow and Underflow\n",
    "- A single subtraction may kill most of the significant digits. This is very '**loss of significance**', which is often called '*catastrophic cancellation*'. In order to prevent 'loss of significance', it is important to avoid a '*bad subtraction*' -- that is, a subtraction of a number from another number having almost equal value.  \n",
    "- In order to decrease the magnitude of round-off errors and to lower the possibility of overflow / underflow errors, make the intermediate result as cloase to **`1`** as possible in consecutive multiplication / division processes. According to this rule, when computing $xy/z$, we program the formula as  \n",
    " - $\\frac{\\big(xy\\big)}{z}$ when $x$ and $y$ in the multiplication are very different in magnitude,  \n",
    " - $x\\big(\\frac{y}{z}\\big)$ when $y$ and $z$ in the division are close in magnitude, and  \n",
    " - $\\big(\\frac{x}{z}\\big)y$ when $x$ and $z$ in the division are close in magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice, practice, and more practices ...**\n",
    "- 1D Brownian motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 1D Brownian motion\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "from IPython import display\n",
    "\n",
    "N = 1000\n",
    "x = np.zeros(N)\n",
    "y = np.zeros(len(x))\n",
    "xaxis = np.linspace(-10, 10,  20)\n",
    "yaxis = np.zeros(len(xaxis))\n",
    "dx = 0.1\n",
    "fig = pl.figure(figsize=(12,8), dpi=120)\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax2 = fig.add_subplot(212)\n",
    "\n",
    "nsteps = 100\n",
    "for n in range(nsteps):\n",
    "    ax1.cla()\n",
    "    ax1.plot(xaxis, yaxis, 'k-')\n",
    "    ax1.scatter(x, y, s = 300, alpha=0.05);\n",
    "    ax1.set_xlim(np.min(xaxis), np.max(xaxis))\n",
    "    ax1.set_ylim(-0.1, 0.1)\n",
    "    ax1.set_title('n = {} teps'.format(n))\n",
    "    \n",
    "    ax2.cla()\n",
    "    ax2.hist(x, bins=20)\n",
    "    ax2.set_xlim(np.min(xaxis), np.max(xaxis))\n",
    "    \n",
    "    _ = display.clear_output(wait=True)\n",
    "    _ = display.display(fig)\n",
    "    \n",
    "    # update location\n",
    "    '''\n",
    "    for i in range(N):\n",
    "        if np.random.rand(1) > 0.5:\n",
    "            x[i] += dx\n",
    "        else:\n",
    "            x[i] -= dx\n",
    "    '''\n",
    "\n",
    "    x += dx * np.sign(np.random.rand(N) - 0.5)\n",
    "\n",
    "pl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2D Brownian motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Brownian motion\n",
    "\n",
    "N = 101\n",
    "X, Y = np.meshgrid(np.linspace(-2, 2, N), np.linspace(-2, 2, N))\n",
    "dx = .1\n",
    "dy = .1\n",
    "\n",
    "fig = pl.figure(figsize=(12,8), dpi=120)\n",
    "ax = fig.subplots()\n",
    "nsteps = 100;\n",
    "for n in range(nsteps):\n",
    "    ax.cla()\n",
    "    ax.plot(X, Y, 'k.')\n",
    "    ax.axis('square')\n",
    "    ax.set_xlim(-10, 10)\n",
    "    ax.set_ylim(-10, 10)\n",
    "    ax.set_title('n = {} steps'.format(n))\n",
    "    _ = display.clear_output(wait=True)\n",
    "    _ = display.display(fig)\n",
    "    '''\n",
    "    for j in range(N):\n",
    "        for i in range(N):\n",
    "            if np.random.rand(1) > 0.5:\n",
    "                X[i][j] += dx\n",
    "            else:\n",
    "                X[i][j] -= dx\n",
    "            \n",
    "            if np.random.rand(1) > 0.5:\n",
    "                Y[i][j] += dy\n",
    "            else:\n",
    "                Y[i][j] -= dy\n",
    "    '''\n",
    "    \n",
    "    X += dx * np.sign(np.random.rand(np.size(X,0), np.size(X,1)) - 0.5);\n",
    "    Y += dy * np.sign(np.random.rand(np.size(Y,0), np.size(Y,1)) - 0.5);\n",
    "\n",
    "pl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Systems of Linear Algebraic Equations\n",
    "- Solve the simultaneous equations $\\mathbf{Ax=b}$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "A_{11}x_1+A_{12}x_2+\\dots+A_{1n}x_n&=b_1\\\\\n",
    "A_{21}x_1+A_{22}x_2+\\dots+A_{2n}x_n&=b_2\\\\\n",
    "A_{31}x_1+A_{32}x_2+\\dots+A_{3n}x_n&=b_3\\\\\n",
    " &\\quad \\vdots\\\\\n",
    "A_{n1}x_1+A_{n2}x_2+\\dots+A_{nn}x_n&=b_n\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "A_{11} & A_{12} & \\dots & A_{1n} \\\\\n",
    "A_{21} & A_{22} & \\dots & A_{2n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "A_{n1} & A_{n2} & \\dots & A_{nn} \\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x1 \\\\\n",
    "x2 \\\\\n",
    "\\vdots \\\\\n",
    "x_n\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "b_1 \\\\\n",
    "b_2 \\\\\n",
    "\\vdots \\\\\n",
    "b_n\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\\mathbf{Ax}=\\mathbf{b}$$\n",
    "\n",
    "$$\n",
    "\\big[\\mathbf{A}|\\mathbf{b}\\big]=\\begin{bmatrix}\n",
    "\\begin{array}{cccc|c}\n",
    "A_{11} & A_{12} & \\dots & A_{1n} & b_1\\\\\n",
    "A_{21} & A_{22} & \\dots & A_{2n} & b_2\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots& \\vdots \\\\\n",
    "A_{n1} & A_{n2} & \\dots & A_{nn} & b_n\\\\\n",
    "\\end{array} \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Uniqueness of Solution\n",
    " - $\\left\\{\\begin{align}\n",
    "     &2x+y=3\\\\\n",
    "     &4x+2y=6\n",
    "   \\end{align}\\right ., \\quad$ \n",
    "   $\\left\\{\\begin{align}\n",
    "     &2x+y=3\\\\\n",
    "     &4x+2y=0\n",
    "   \\end{align}\\right .$\n",
    "- Conditioning\n",
    " - coefficient (determinant) of the matrix\n",
    "   - $|\\mathbf{A}|$\n",
    " - norm of the matrix\n",
    "   - $\\|\\mathbf{A}\\|$\n",
    " - condition of the matrix\n",
    "   - $cond(A)=\\|\\mathbf{A}\\|\\|\\mathbf{A}^{-1}\\|$\n",
    " - when condition number is big, the matrix is **ill-conditioned**\n",
    " - e.g.<br/>\n",
    "   $\\left\\{\\begin{align}\n",
    "     &2x+y=3\\\\\n",
    "     &2x+1.001y=0\n",
    "   \\end{align}\\right .$\n",
    "   \n",
    "   $|\\mathbf{A}|=\\left|\\begin{matrix}\n",
    "   2 & 1 \\\\ 2 & 1.001\n",
    "   \\end{matrix}\\right|=2\\times1.001-2\\times1=0.002$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[2, 1], [2, 1.001]])\n",
    "A_inv = np.linalg.inv(A)\n",
    "A_norm = np.linalg.norm(A)\n",
    "A_inv_norm = np.linalg.norm(A_inv)\n",
    "A_cond = np.linalg.cond(A)\n",
    "\n",
    "A_cond - A_norm * A_inv_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct Methods\n",
    "\n",
    "| Method | Initial Form | Final Form |\n",
    "|:------:|:------------:|:----------:|\n",
    "| Gauss Elimination | $\\mathbf{Ax}=\\mathbf{b}$ | $\\mathbf{Ux}=\\mathbf{c}$ |\n",
    "| LU Decomposition | $\\mathbf{Ax}=\\mathbf{b}$ | $\\mathbf{LUx}=\\mathbf{b}$ |\n",
    "| Gauss-Jordan Elimination | $\\mathbf{Ax}=\\mathbf{b}$ | $\\mathbf{Ix}=\\mathbf{c}$ |\n",
    "\n",
    "$$\n",
    "\\mathbf{U}=\\begin{bmatrix}\n",
    "U_{11} & U_{12} & U_{13} & \\dots & U_{1n}\\\\\n",
    "     0 & U_{22} & U_{23} & \\dots & U_{2n}\\\\\n",
    "     0 &      0 & U_{33} & \\dots & U_{3n}\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots& \\vdots\\\\\n",
    "     0 &      0 &     0  & \\dots & U_{nn}\\\\\n",
    "\\end{bmatrix}, \\quad \n",
    "\\mathbf{L}=\\begin{bmatrix}\n",
    "L_{11} &     0  &     0  & \\dots &     0 \\\\\n",
    "L_{21} & L_{22} &     0  & \\dots &     0 \\\\\n",
    "L_{31} & L_{32} & L_{33} & \\dots &     0 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots&     0 \\\\\n",
    "L_{n1} & L_{n2} & L_{n3} & \\dots & L_{nn}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "L_{11}x_1 &= c_1\\\\\n",
    "L_{21}x_1+L_{22}x_2 &= c_2\\\\\n",
    "L_{31}x_1+L_{32}x_2+L_{33}x_3 &= c_3\\\\\n",
    "&\\quad \\vdots \\\\\n",
    "L_{n1}x_1+L_{n2}x_2+L_{n3}x_3+\\dots+L_{nn}x_n &= c_n\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\\big\\Downarrow$$\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x_1 &= c_1/L_{11}\\\\\n",
    "x_2 &= \\left(c_2-L_{21}x_1\\right)/L_{22}\\\\\n",
    "x_3 &= \\left(c_3-L_{31}x_1-L_{32}x_2\\right)/L_{33}\\\\\n",
    "    &\\quad \\vdots\\\\\n",
    "x_n &= \\left(c_n-L_{n1}x_1-L_{n2}x_2-L_{n3}x_3-\\dots-L_{n,n-1}x_{n-1}\\right)/L_{nn} \\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "<br/>\n",
    "\n",
    "$$\n",
    "\\begin{gather}\n",
    "\\mathbf{LUx}=\\mathbf{b}\\\\\n",
    "\\text{let }\\mathbf{y}=\\mathbf{Ux},\\\\\n",
    "\\text{then solve }\\mathbf{Ly}=\\mathbf{b} \\text{ for }\\mathbf{y},\\\\\n",
    "\\text{and finally solve }\\mathbf{Ux}=\\mathbf{y} \\text{ for }\\mathbf{x}.\n",
    "\\end{gather}\n",
    "$$  \n",
    "\n",
    "<br/>\n",
    "\n",
    "- Examples\n",
    "\n",
    "$$\n",
    "\\mathbf{A}=\\begin{bmatrix}\n",
    "2.1 & -0.6 &  1.1\\\\\n",
    "3.2 &  4.7 & -0.8\\\\\n",
    "3.1 & -6.5 &  4.1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "|\\mathbf{A}|=2.1\\left|\\begin{matrix}\n",
    "4.7  & -0.8\\\\\n",
    "-6.5 &  4.1\n",
    "\\end{matrix}\\right|\n",
    "+0.6\\left|\\begin{matrix}\n",
    "3.2 & -0.8\\\\\n",
    "3.1 &  4.1 \n",
    "\\end{matrix}\\right|\n",
    "-1.1\\left|\\begin{matrix}\n",
    "3.2 &  4.7\\\\\n",
    "3.1 & -6.5\n",
    "\\end{matrix}\\right|=2.1\\times14.07+0.6\\times15.60+1.1\\times35.37=0\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "A = np.array([[2.1, -0.6, 1.1], [3.2, 4.7, -0.8], [3.1, -6.5, 4.1]])\n",
    "np.linalg.det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{A}=\\begin{bmatrix}\n",
    " 8 & -6 &  2\\\\\n",
    "-4 & 11 & -7\\\\\n",
    " 4 & -7 &  6\n",
    "\\end{bmatrix},\\ \n",
    "\\mathbf{b}=\\begin{bmatrix}\n",
    "28 \\\\ -40 \\\\ 33\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{A}=\\mathbf{LU}=\n",
    "\\begin{bmatrix}\n",
    " 2 &  0 & 0\\\\\n",
    "-1 &  2 & 0\\\\\n",
    " 1 & -1 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "4 & -3 &  1\\\\\n",
    "0 &  4 & -3\\\\\n",
    "0 &  0 &  2\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg\n",
    "\n",
    "A = np.array([[8,-6,2], [-4,11,-7], [4,-7,6]])\n",
    "p,l,u = linalg.lu(A)\n",
    "print('l =', l)\n",
    "print('u =', u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve $\\mathbf{Ly}=\\mathbf{b}$ for $\\mathbf{y}$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "2y_1&=28\\\\\n",
    "-y_1+2y_2&=-40\\\\\n",
    "y_1-y_2+y_3&=33\n",
    "\\end{aligned}\\quad\n",
    "\\begin{aligned}\n",
    "y_1&=28/2=14\\\\\n",
    "y_2&=(-40+y_1)/2=(-40+14)/2=-13\\\\\n",
    "y_3&=33-y_1+y_2=33-14-13=6\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Solve $\\mathbf{Ux}=\\mathbf{y}$ for $\\mathbf{x}$, inversely:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "2x_3&=y_3\\\\\n",
    "4x_2-3x_3&=y_2\\\\\n",
    "4x_1-3x_2+x_3&=y_1\n",
    "\\end{aligned}\\quad\n",
    "\\begin{aligned}\n",
    "x_3&=y_3/2=6/2=3\\\\\n",
    "x_2&=(y_2+3x_3)/4=(-13+3\\times3)/4=-1\\\\\n",
    "x_1&=(y_1+3x_2-x_3)/4=[14+3\\times(-1)-3]/4=2\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gauss Elimination Method\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "4x_1-2x_2+x_3&=11\\quad &(a)\\\\\n",
    "-2x_1+4x_2-2x_3&=-16\\quad &(b)\\\\\n",
    "x_1-2x_2+4x_3&=17\\quad &(c)\n",
    "\\end{align*}\\quad\\quad\\quad\n",
    "\n",
    "\\begin{bmatrix}\n",
    "\\begin{array}{ccc|c}\n",
    "4 & -2 & 1 & 11\\\\\n",
    "-2 & 4 & -2 & -16\\\\\n",
    "1 & -2 & 4 & 17\n",
    "\\end{array} \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{Eq. (b)} &\\leftarrow \\text{Eq. (b)}-(-0.5)\\times\\text{Eq. (a)}\\\\\n",
    "\\text{Eq. (c)} &\\leftarrow \\text{Eq. (c)}-0.25\\times\\text{Eq. (a)}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "4x_1-2x_2+x_3&=11.0\\quad &(a)\\\\\n",
    "3x_2-1.5x_3&=-10.5\\quad &(b)\\\\\n",
    "-1.5x_2+3.75x_3&=14.25\\quad &(c)\n",
    "\\end{align*}\\quad\\quad\\quad\n",
    "\\begin{bmatrix}\\begin{array}{ccc|c}\n",
    "4 & -2 & 1 & 11.0\\\\\n",
    "0 &  3 & -1.5 & -10.50\\\\\n",
    "0 & -1.5 & 3.75 & 14.25\n",
    "\\end{array}\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$\\text{Eq. (c)} \\leftarrow \\text{Eq. (c)}-(-0.5)\\times\\text{Eq. (b)}$\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "4x_1-2x_2+x_3&=11.0\\quad &(a)\\\\\n",
    "3x_2-1.5x_3&=-10.5\\quad &(b)\\\\\n",
    "3x_3&=9.0\\quad &(c)\n",
    "\\end{align*}\\quad\\quad\\quad\n",
    "\\begin{bmatrix}\\begin{array}{ccc|c}\n",
    "4 & -2 & 1 & 11.0\\\\\n",
    "0 &  3 & -1.5 & -10.50\\\\\n",
    "0 &  0 & 3 & 9.0\n",
    "\\end{array}\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "x_3&=9/3=3\\\\\n",
    "x_2&=(-10.5+1.5x_3)/3=(-10.5+1.5\\times3)/3=-2\\\\\n",
    "x_1&=(11+2x_2-x_3)/4=[11+2\\times(-2)-3]/4=1\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg\n",
    "\n",
    "A = np.array([[4,-2,1], [-2,4,-2], [1,-2,4]])\n",
    "b = np.array([11, -16, 17])\n",
    "linalg.solve(A, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gauss Elimination Method:\n",
    "- Elimination Phase\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\\begin{array}{ccccccccc|c}\n",
    "A_{11} & A_{12} & A_{13} & \\dots & A_{1k} & \\dots & A_{1j} & \\dots & A_{1n} & b_1\\\\\n",
    "    0  & A_{22} & A_{23} & \\dots & A_{2k} & \\dots & A_{2j} & \\dots & A_{2n} & b_2\\\\\n",
    "    0  &     0  & A_{33} & \\dots & A_{3k} & \\dots & A_{3j} & \\dots & A_{3n} & b_3\\\\\n",
    "\\vdots & \\vdots & \\vdots & & \\vdots & & \\vdots & & \\vdots & \\vdots\\\\\n",
    "0 & 0 & 0 & \\dots & A_{kk} & \\dots & A_{kj} & \\dots & A_{kn} & b_k\\\\\n",
    "\\hline\n",
    "\\vdots & \\vdots & \\vdots & & \\vdots & & \\vdots & & \\vdots & \\vdots\\\\\n",
    "0 & 0 & 0 & \\dots & A_{ik} & \\dots & A_{ij} & \\dots & A_{in} & b_i\\\\\n",
    "\\vdots & \\vdots & \\vdots & & \\vdots & & \\vdots & & \\vdots & \\vdots\\\\\n",
    "0 & 0 & 0 & \\dots & A_{nk} & \\dots & A_{nj} & \\dots & A_{nn} & b_n\\\\\n",
    "\\end{array}\\end{bmatrix}\n",
    "\\begin{array}{l}\n",
    "\\\\ \\\\ \\\\ \\\\\n",
    "\\leftarrow \\text{pivot row}\\\\\n",
    "\\\\\n",
    "\\leftarrow \\text{row being}\\\\\n",
    "\\quad \\text{transformed}\\\\ \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "A_{ij} & \\leftarrow A_{ij}-\\lambda A_{kj},\\quad j=k,k+1,\\dots,n\\\\\n",
    "b_i & \\leftarrow b_i-\\lambda b_k\n",
    "\\end{align}\\quad\\quad\\quad\n",
    "\\lambda=A_{ik}/A_{kk}\n",
    "$$\n",
    "\n",
    "<br/>\n",
    "\n",
    "```python\n",
    "for k in range(n):\n",
    "    for i in range(k+1,n):\n",
    "        if A[i,k] != 0:\n",
    "            lambda_ = A[i,k]/A[k,k]\n",
    "            A[i,k+1:n] = A[i,k+1:n] - lambda_ * A[k,k+1:n]\n",
    "            b[i] = b[i] - lambda_ * b[k]\n",
    "```\n",
    "\n",
    "$~n^3/3$ steps, $O(n^3)$\n",
    "\n",
    "<br/>\n",
    "\n",
    "- Back Substitution Phase\n",
    "\n",
    "$$\n",
    "\\left[\\mathbf{A}|\\mathbf{b}\\right]=\\begin{bmatrix}\n",
    "\\begin{array}{ccccc|c}\n",
    "A_{11} & A_{12} & A_{13} & \\dots & A_{1n} & b_1\\\\\n",
    "    0  & A_{22} & A_{23} & \\dots & A_{2n} & b_2\\\\\n",
    "    0  &     0  & A_{33} & \\dots & A_{3n} & b_3\\\\\n",
    "\\vdots & \\vdots & \\vdots &       & \\vdots & \\vdots\\\\\n",
    "    0  &     0  &     0  & \\dots & A_{nn} & b_n\\\\\n",
    "\\end{array}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$x_n=b_n/A_{nn}$$\n",
    "\n",
    "$$A_{kk}x_{k}+A_{k,k+1}x_{k+1}+\\dots+A_{kn}x_n=b_k$$\n",
    "\n",
    "$$x_k=\\left(b_k-\\sum_{j=k+1}^{n}A_{kj}x_j\\right)\\frac{1}{A_{kk}},\\quad k=n-1,n-2,\\dots,1$$\n",
    "\n",
    "<br/>\n",
    "\n",
    "```python\n",
    "b[-1] = b[-1] / A[-1,-1]\n",
    "for k in range(n-2, -1, -1):\n",
    "    b[k] = (b[k] - A[k,k+1:-1]*b[k+1:-1])/A[k,k]\n",
    "```\n",
    "\n",
    "$~n^2/2$ steps, $O(n^2)$\n",
    "\n",
    "<br/>\n",
    "\n",
    "- Code and Examples\n",
    "\n",
    "An $n\\times n$ Vandermode matrix $\\mathbf{A}$ is defined by\n",
    "$$A_{ij}=v_{i}^{n-j},\\quad i=1,2,\\dots,n,\\quad j=1,2,\\dots,n$$\n",
    "\n",
    "$$v=\\big[1.0\\ \\ 1.2\\ \\ 1.4\\ \\ 1.6\\ \\ 1.8\\ \\ 2.0\\big]^\\mathrm{T}$$\n",
    "\n",
    "$$\\mathbf{b}=\\big[0\\ \\ 1\\ \\ 0 \\ \\ 1 \\ \\ 0\\ \\ 1\\big]^\\mathrm{T}$$\n",
    "\n",
    "$$\\mathbf{x}=\\big[1250/3\\ \\ -3125\\ \\ 9250\\ \\ -13500\\ \\ 29128/3\\ \\ -2751\\big]^\\mathrm{T}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "v = np.linspace(1, 2, 6)\n",
    "A = np.vander(v)\n",
    "b = np.array([0, 1, 0, 1, 0, 1], dtype=np.float)\n",
    "true_res = np.array([1250/3, -3125, 9250, -13500, 29128/3, -2751])\n",
    "np.linalg.solve(A, b) - true_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss(A, b):\n",
    "    '''Solves A*x = b by Gauss elimination and computes det(A)'''\n",
    "    A = np.copy(A)\n",
    "    b = np.copy(b)\n",
    "    n = len(b)\n",
    "    # Elimination phase\n",
    "    for k in range(n - 1):\n",
    "        for i in range(k + 1, n):\n",
    "            if A[i, k] != 0:\n",
    "                lambda_ = A[i, k] / A[k ,k]\n",
    "                A[i, k + 1 : n] = A[i, k + 1 : n] - lambda_ * A[k, k + 1 : n]\n",
    "                b[i] = b[i] - lambda_ * b[k]\n",
    "    \n",
    "    # Back substitution phase\n",
    "    det = np.prod(np.diag(A))\n",
    "    b[-1] = b[-1] / A[-1, -1]\n",
    "    for k in range(n-2, -1, -1):\n",
    "        b[k] = (b[k] - A[k, k + 1 : n].dot(b[k + 1 : n])) / A[k ,k]\n",
    "\n",
    "    # x = b\n",
    "    return b, det\n",
    "\n",
    "x, _ = gauss(A, b)\n",
    "print(x - true_res)\n",
    "x, _ = gauss(A, b)\n",
    "print(x - true_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LU Decomposition\n",
    "\n",
    "- Advantage: once $\\mathbf{A}$ is decomposed, we can solve $\\mathbf{Ax}=\\mathbf{b}$ for as many constant vectors $\\mathbf{b}$ as we like.\n",
    "\n",
    "- The computation cost is about the same as Gauss elimination, $n^3/3$.\n",
    "\n",
    "$$\n",
    "\\mathbf{L}=\\begin{bmatrix}\n",
    "1 & 0 & 0 & \\dots & 0 & 0\\\\\n",
    "L_{21} & 1 & 0 & \\dots & 0 & 0\\\\\n",
    "L_{31} & L_{32} & 1 & \\dots & 0 & 0\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots\\\\\n",
    "L_{n-1,1} & L_{n-1,2} & L_{n-1,3} & \\dots & 1 & 0\\\\\n",
    "L_{n1} & L_{n2} & L_{n3} & \\dots & L_{n,n-1} & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{U}=\\begin{bmatrix}\n",
    "U_{11} & U_{12} & U_{13} & \\dots & U_{1,n-1} & U_{1n}\\\\\n",
    "     0 & U_{22} & U_{23} & \\dots & U_{2,n-1} & U_{2n}\\\\\n",
    "     0 &      0 & U_{33} & \\dots & U_{3,n-1} & U_{3n}\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots& \\vdots & \\vdots\\\\\n",
    "     0 &      0 &     0  & \\dots & U_{n-1,n-1} & U_{n-1,n}\\\\\n",
    "     0 &      0 &     0  & \\dots & 0 & U_{nn}\\\\\n",
    "\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\mathbf{A}=\\begin{bmatrix}\n",
    "U_{11} & U_{12} & U_{13} & \\dots \\\\\n",
    "U_{11}L_{21} & U_{12}L_{21}+U_{22} & U_{13}L_{21}+U_{23} & \\dots \\\\\n",
    "U_{11}L_{31} & U_{12}L_{31}+U_{22}L_{32} & U_{13}L_{31}+U_{23}L_{32}+U_{33} & \\dots\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choleski's Decomposition Method: $\\mathbf{A}=\\mathbf{LL}^{\\mathrm{T}}$\n",
    "\n",
    "- Since the matrix product $\\mathbf{LL}^{\\mathrm{T}}$ is always symmetric, Choleski's decomposition can be applied only to *symmetric* matrices.\n",
    "\n",
    "- The decomposition process involves taking square roots of certain combinations of the elements of $\\mathbf{A}$. It can be shown that square roots of negative numbers can be avoided only if $\\mathbf{A}$ is positive definite.\n",
    "\n",
    "- Choleski's decomposition contains approximately $n^3/6$ operations plus $n$ square root computations. This is about half the number of operations required in LU decomposition. The relative efficiency of Choleski's decomposition is due to its exploitation of symmetry.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "A_{11} & A_{12} & A_{13} & \\dots\\\\\n",
    "A_{21} & A_{22} & A_{23} & \\dots\\\\\n",
    "A_{31} & A_{32} & A_{33} & \\dots\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \n",
    "\\end{bmatrix}\n",
    "=\\begin{bmatrix}\n",
    "L_{11} &     0  &    0   & \\dots\\\\\n",
    "L_{21} & L_{22} &    0   & \\dots\\\\\n",
    "L_{31} & L_{32} & L_{33} & \\dots\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "L_{11} & L_{21} & L_{31} & \\dots\\\\\n",
    "    0  & L_{22} & L_{32} & \\dots\\\\\n",
    "    0  &     0  & L_{33} & \\dots\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "A_{11} & A_{12} & A_{13} & \\dots\\\\\n",
    "A_{21} & A_{22} & A_{23} & \\dots\\\\\n",
    "A_{31} & A_{32} & A_{33} & \\dots\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \n",
    "\\end{bmatrix}\n",
    "=\\begin{bmatrix}\n",
    "L_{11}^2 & L_{11}L_{21} & L_{11}L_{31} & \\dots\\\\\n",
    "L_{11}L_{21} & L_{21}^2L_{22}^2 & L_{21}L_{31}+L_{22}L_{32} & \\dots\\\\\n",
    "L_{11}L_{31} & L_{21}L_{31}+L_{22}L_{32} & L_{31}^2+L_{32}^2+L_{33}^2 & \\dots\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "A_{11}&=L_{11}^2\\\\\n",
    "A_{21}&=L_{11}L_{21}\\\\\n",
    "A_{31}&=L_{11}L_{31}\n",
    "\\end{aligned}\\quad\n",
    "\\begin{aligned}\n",
    "L_{11}&=\\sqrt{A_{11}}\\\\\n",
    "L_{21}&=A_{21}/L_{11}\\\\\n",
    "L_{31}&=A_{31}/L_{11}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "A_{22}&=L_{21}^2+L_{22}^2\\\\\n",
    "A_{32}&=L_{21}L_{31}+L_{22}L_{32}\n",
    "\\end{aligned}\\quad\n",
    "\\begin{aligned}\n",
    "L_{22}&=\\sqrt{A_{22}-L_{21}^2}\\\\\n",
    "L_{32}&=\\left(A_{32}-L_{21}L_{31}\\right)/L_{22}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "$$A_{33}=L_{31}^2+L_{32}^2+L_{33}^2\\quad L_{33}=\\sqrt{A_{33}-L_{31}^2-L_{32}^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Methods\n",
    "\n",
    "- Gauss-Jordan Elimination\n",
    "- Symmetric and Banded Coefficient Matrices\n",
    "- **Tridiagonal Coefficient Matrix**\n",
    "- Symmetric, Pentadiagonal Coefficient Matrices\n",
    "- Pivoting\n",
    "- Diagonal Dominance\n",
    "- Matrix Inversion (simply let $b=n\\times n$ identity matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indirect Methods (Iterative Methods)\n",
    "\n",
    "- Advantage of direct methods: compute the solution with a fixed number of operations, and if the computer were capable of infinite precision (no roundoff errors), the solution would be exact.\n",
    "\n",
    "- Iterative methods or indirect methods start with an initial guess of the solution $\\mathbf{x}$ and then repeatedly improve the solution until the change in $\\mathbf{x}$ become negligible. Since the required number of iterations can be very large, the indirect methods are, in general, slower than their direct counterparts.\n",
    "\n",
    "- But iterative methods are feasible to store only the nonzero elements of the coefficient matrix. This makes them possible to deal with very large matrices that are sparse, but not necessarily banded. In many problems, there is no need to store the coefficient matrix at all.\n",
    "\n",
    "- Iterative procedures are self-correcting meaning that roundoff errors (or even arithmetic mistakes) in one iterative cycle are corrected in subsequent cycles.\n",
    "\n",
    "- A serous drawback of iterative methods is that they do not always converge to the solution. It can be shown that convergence is guaranteed only if the coefficient matrix is diagonally dominant. The initial guess for $\\mathbf{x}$ plays no role in determining whether convergence takes place - if the procedure converges for one starting vector, it would do so for any starting vector. The initial guess affects only the number of iterations that are required for convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gauss-Seidel Method\n",
    "\n",
    "The equations $\\mathbf{Ax}=\\mathbf{b}$ are in scalar notation\n",
    "\n",
    "$$\\sum_{j=1}^n A_{ij}x_j=b_i,\\quad i=1,2,\\dots,n$$\n",
    "\n",
    "Extracting the term containing $x_i$ from the summation sign yields\n",
    "\n",
    "$$A_{ii}x_i+\\sum_{j=1\\\\j\\neq i}^n A_{ij}x_j=b_i,\\quad i=1,2,\\dots,n$$\n",
    "\n",
    "Solving for $x_i$, we get\n",
    "\n",
    "$$x_i=\\frac{1}{A_{ii}}\\left(b_i-\\sum_{j=1\\\\j\\neq i}^n A_{ij}x_j\\right),\\quad i=1,2,\\dots,n$$\n",
    "\n",
    "The last equation suggests the following iterative scheme\n",
    "\n",
    "$$x_i\\leftarrow\\frac{1}{A_{ii}}\\left(b_i-\\sum_{}^n A_{ij}x_j\\right),\\quad i=1,2,\\dots,n$$\n",
    "\n",
    "We start by choosing the starting vector $\\mathbf{x}$. If a good guess for the solution is not available, $\\mathbf{x}$ can be chosen randomly. The equation is then used to recompute each element of $\\mathbf{x}$, always using the latest available values of $x_j$. This completes one iteration cycle. The procedure is repeated until the changes in $\\mathbf{x}$ between successive iteration cycles become sufficiently small.\n",
    "\n",
    "**Example**\n",
    "\n",
    "Solve the equations\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "4 & -1 & 1\\\\\n",
    "-1 & 4 & -2\\\\\n",
    "1 & -2 & 4\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "x_1\\\\x_2\\\\x_3\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "12\\\\-1\\\\5\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "by the Gauss-Seidel method without relaxation.\n",
    "\n",
    "Let us start with $\\mathbf{x}=0$.\n",
    "\n",
    "$$\n",
    "\\left\\{\\begin{aligned}\n",
    "x_1&=\\frac{1}{4}\\left(12+x_2-x_3\\right)\\\\\n",
    "x_2&=\\frac{1}{4}\\left(-1+x_1+2x_3\\right)\\\\\n",
    "x_3&=\\frac{1}{4}\\left(5-x_1+2x_2\\right)\n",
    "\\end{aligned}\\right .\\Rightarrow\n",
    "\\left\\{\\begin{aligned}\n",
    "x_1&=\\frac{1}{4}\\left(12+0-0\\right)=3\\\\\n",
    "x_2&=\\frac{1}{4}\\left(-1+3+2\\times0\\right)=0.5\\\\\n",
    "x_3&=\\frac{1}{4}\\left(5-3+2\\times0.5\\right)\n",
    "\\end{aligned}\\right .\\Rightarrow\n",
    "\\left\\{\\begin{aligned}\n",
    "x_1&=\\frac{1}{4}\\left(12+0.5-0.75\\right)=2.9375\\\\\n",
    "x_2&=\\frac{1}{4}\\left(-1+2.9375+2\\times0.75\\right)=0.85938\\\\\n",
    "x_3&=\\frac{1}{4}\\left(5-2.9375+2\\times0.85938\\right)=0.94531\n",
    "\\end{aligned}\\right .\\Rightarrow\n",
    "\\left\\{\\begin{aligned}\n",
    "x_1&=\\frac{1}{4}\\left(12+0.85938-0.94531\\right)=2.97852\\\\\n",
    "x_2&=\\frac{1}{4}\\left(-1+2.97852+2\\times0.94531\\right)=0.96729\\\\\n",
    "x_3&=\\frac{1}{4}\\left(5-2.97852+2\\times0.96729\\right)=0.98902\n",
    "\\end{aligned}\\right .\\Rightarrow\\dots\n",
    "$$\n",
    "\n",
    "After five more iterations the results would agree with the exact solution $x_1=3,x_2=x_3=1$ within five decimal places."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gauss-Seidel Method with Relaxation\n",
    "\n",
    "Convergence of Gauss-Seidel method can be improved by a technique known as *relaxation*. The idea is to take the new value of $x_i$ as a weighted average of its previous value and the value predicted by the iterative scheme. The corresponding iterative formula is\n",
    "\n",
    "$$\n",
    "x_i\\leftarrow\\frac{\\omega}{A_{ii}}\\left(b_i-\\sum_{j=1\\\\j\\neq i}^n A_{ij}x_j\\right)+\\left(1-\\omega\\right)x_i,\\quad i=1,2,\\dots,n\n",
    "$$\n",
    "\n",
    "where the weight $\\omega$ is called the *relaxation* factor. It can be seen that if <font color=#0099ff>$\\omega=1$</font>, no relaxation takes place. if <font color=#0099ff>$\\omega<1$</font>, it represents interpolation between the old $x_i$ and the value given by the equation. This is called **under-relaxation**. In cases where <font color=#0099ff>$\\omega>1$</font>, we have extrapolation, or **over-relaxation**.\n",
    "\n",
    "<br/>\n",
    "There is no practical method of determining the optimal value of $\\omega$ beforehand; however, a good estimate can be computed during run time. let $\\Delta x^{(k)}=\\left|\\mathbf{x}^{(k-1)}-\\mathbf{x}^{(k)}\\right|$ be the magnitude of the change in $\\mathbf{x}$ during the $k$th iteration (carried out without relaxation, i.e., with $\\omega=1$). If $k$ is sufficiently large (say, $k\\geq5$), it can be shown that an approximation of the optimal value of $\\omega$ is\n",
    "\n",
    "$$\n",
    "\\omega_{opt}\\approx\\frac{2}{1+\\sqrt{1-\\left(\\Delta x^{(k+p)}/\\Delta x^{(k)}\\right)^{1/p}}}\n",
    "$$\n",
    "\n",
    "where $p$ is a positive inter.\n",
    "\n",
    "The essential elements of a Gauss-Seidel algorithm with relaxation are:\n",
    "\n",
    "1. Carry out $k$ iterations with $\\omega=1$ ($k=10$ is reasonable). After the $k$th iteration record $\\Delta x^{(k)}$.\n",
    "2. Perform an additional $p$ iterations ($p\\geq1)$, and record $\\Delta x^{(k+p)}$ after the last iteration.\n",
    "3. Perform all subsequent iterations with $\\omega=\\omega_{opt}$, where $\\omega_{opt}$ is computed using the formula above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conjugate Gradient Method\n",
    "\n",
    "- It appears that the conjugate gradient algorithm is not an iterative method at all, since it reaches the exact solution after $n$ computational cycles. In practice, however, convergence is usually achieved in less than $n$ iterations.\n",
    "\n",
    "- Conjugate gradient method is not competitive with direct methods in the solution of small sets of equations. Its strength lies in the handling of large, sparse systems (where most elements of $\\mathbf{A}$ are zero)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "1. EXAMPLE 2.17 on *Numerical Methods in Engineering with MATLAB*, 2nd Edition.\n",
    "\n",
    "&nbsp;&nbsp;Tasks:\n",
    "\n",
    "&nbsp;&nbsp; (1) figure out how to derive the exact solution;  \n",
    "&nbsp;&nbsp; (2) figure out how to derive the iterative formula;  \n",
    "&nbsp;&nbsp; (3) run the code, fex2_17 and gaussSeidel given on the textbook, and see if you could get the same results;  \n",
    "&nbsp;&nbsp; (4) run the code several times and compare the speed with MATLAB intrinsic `\\` operator or Python `scipy.linalg.solve` function; plot the results as computation speed on y-axis vs. matrix size on x-axis.\n",
    "\n",
    "\n",
    "2. PROBLEM SET 2.3 on *Numerical Methods in Engineering with MATLAB*, 2nd Edition.\n",
    " - 1 ~ 7, and 9, if you don't know how to calculate, you should use the `inv` function given by MATLAB or Python to do so, at least.\n",
    " - 10\n",
    " - 11, 12, 13, 16\n",
    " - 17\n",
    " - 19, just use MATLAB `\\` or Python `scipy.linalg.solve`. This is your first PDE!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix Inversion Speed Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speed comparison of matrix inversion using inv and solve\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 20\n",
    "m = np.round(np.logspace(1, 3, N)).astype(np.int)\n",
    "time_cost = np.zeros((N, 2))\n",
    "\n",
    "ntimes = 5\n",
    "for i in range(len(m)):\n",
    "    A = np.random.rand(m[i], m[i])\n",
    "    I = np.eye(m[i])\n",
    "\n",
    "    start = time.time()\n",
    "    for n in range(ntimes):\n",
    "        np.linalg.inv(A)\n",
    "\n",
    "    time_cost[i][0] = (time.time() - start) / ntimes\n",
    "\n",
    "    start = time.time()\n",
    "    for n in range(ntimes):\n",
    "        np.linalg.solve(A, I)\n",
    "\n",
    "    time_cost[i][1] = (time.time() - start) / ntimes\n",
    "\n",
    "plt.loglog(m, time_cost[:, 0], 'bo-', m, time_cost[:, 1], 'rx-')\n",
    "plt.title('Speed comparison of matrix inversion')\n",
    "plt.legend(('using inv', 'using solve'))\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
